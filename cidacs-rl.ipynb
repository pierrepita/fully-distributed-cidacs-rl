{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_data': 'yes',\n",
       " 'es_index_name': 'fd-cidacs-rl',\n",
       " 'es_connect_string': 'http://localhost:9200',\n",
       " 'query_size': 50,\n",
       " 'cutoff_exact_match': '0.95',\n",
       " 'null_value': '99',\n",
       " 'datasets_info': {'indexed_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-dataset-A.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_a', 'nome_a', 'nome_mae_a', 'dt_nasc_a', 'sexo_a'],\n",
       "   'id_column_name': 'id_cidacs_a'},\n",
       "  'tolink_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-datasets-b/sinthetic-datasets-b-1000.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_b', 'nome_b', 'nome_mae_b', 'dt_nasc_b', 'sexo_b'],\n",
       "   'id_column_name': 'id_cidacs_b'},\n",
       "  'result_dataset': {'path': '../0_global_data/result/'}},\n",
       " 'comparisons': {'name': {'indexed_col': 'nome_a',\n",
       "   'tolink_col': 'nome_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '3.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02},\n",
       "  'mothers_name': {'indexed_col': 'nome_mae_a',\n",
       "   'tolink_col': 'nome_mae_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '2.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02},\n",
       "  'birthdate': {'indexed_col': 'dt_nasc_a',\n",
       "   'tolink_col': 'dt_nasc_b',\n",
       "   'must_match': 'false',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'hamming',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02},\n",
       "  'sex': {'indexed_col': 'sexo_a',\n",
       "   'tolink_col': 'sexo_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'overlap',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('config.txt')\n",
    "config = json.load(f)\n",
    "config_bc = sc.broadcast(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_match_cols_and_values(vars_col, query_type):\n",
    "    \"\"\"\n",
    "    query_type must be 'exact' for building exact queries or 'general' for any else query and comparison.\n",
    "    \"\"\"\n",
    "    # getting names of indexed columns\n",
    "    indexed_id_column = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    \n",
    "    indexed_cols = config_['datasets_info']['indexed_dataset']['columns']\n",
    "    indexed_cols = [x for x in indexed_cols if x != indexed_id_column]\n",
    "        \n",
    "    # notice that we are linking indexed keys with tolink values\n",
    "    # the keys will be used to set which field will be fetched on es\n",
    "    # the values will be used as search content\n",
    "    tolink_cols_dict = dict(zip(indexed_cols, vars_col))\n",
    "    \n",
    "    if query_type == 'general':\n",
    "        return tolink_cols_dict\n",
    "    elif query_type == 'exact':\n",
    "        # finding which are the columns used on exact match step\n",
    "        indexed_exact_match_vars = [config_['comparisons'][x]['indexed_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']\n",
    "        non_exact_match_cols = list(set(indexed_cols) - set(indexed_exact_match_vars))\n",
    "        # deleting those columns of non-exact match\n",
    "        [tolink_cols_dict.pop(x, None) for x in non_exact_match_cols]\n",
    "        \n",
    "        return tolink_cols_dict\n",
    "    else: \n",
    "        print(\"Please use 'general' or 'exact' as query_type input\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def index_dataframe(dataframe, es_index_name):\n",
    "    # creating new index\n",
    "    dataframe.write.format(\"org.elasticsearch.spark.sql\") \\\n",
    "                 .option(\"es.resource\", es_index_name).mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exact query building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_exact_queries(vars_col): \n",
    "    \"\"\"\n",
    "    Let us suppose the following values:\n",
    "    vars_col = ['ROBESPIERRE PITA', '1987-05-05', '1', 'Mari Santos']\n",
    "    indexed_cols = ['name', 'birthdate', 'sex', 'mothers_name']\n",
    "    query_size = 10\n",
    "    \n",
    "    and only the first two attributes are assigned to exact match.\n",
    "    So, the resulting query column would be: \n",
    "    '{ \"size\": \"50\", \"query\": \n",
    "                    { \"bool\": { \"must\": [ \n",
    "                                {\"match\": {\"name\":\"ROBESPIERRE PITA\"}},\n",
    "                                {\"match\": {\"birthdate\":\"19870505\"}}] } } }'\n",
    "    Requirements: \n",
    "    - All values on vars_col must be converted into string\n",
    "    - All the hyphens symbols must be taken from date type used to search (e.g. 1987-05-05 must be converted to 19870505)\n",
    "    - The config json must be available as a broadcast through sc.broadcast() function.\n",
    "    - The names of indexed columns must be correctly filled. \n",
    "    \"\"\"\n",
    "    config_ = config_bc.value\n",
    "    query_size = config_['query_size']\n",
    "    \n",
    "    tolink_cols_dict = get_match_cols_and_values(vars_col, 'exact')\n",
    "    \n",
    "    # -------------------------------------------- #\n",
    "    #   starting the building of query string      #\n",
    "    # -------------------------------------------- #\n",
    "    # setting the preffix and suffix of query core\n",
    "    prefix_ = \"\"\"{\"match\": {\"\"\"\n",
    "    suffix_ = \"\"\"}}\"\"\"\n",
    "    \n",
    "    # filling the query core with all indexed columns and values from vars_col\n",
    "    strings = []\n",
    "    for col in list(tolink_cols_dict.keys()):\n",
    "        string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \"\\\"\" +  str(tolink_cols_dict[col]) + \"\\\"\" + str(suffix_)\n",
    "        print(string)\n",
    "        strings.append(string)\n",
    "    \n",
    "    # building the query core. \n",
    "    # Should be like: {\"match\": {\"name\":\"ROBESPIERRE PITA\"}}, {\"birthdate\": {\"name\":\"1987-05-05\"}}\n",
    "    line = ','.join(strings)\n",
    "    \n",
    "    # Finally the final query string\n",
    "    complete_query = \"\"\"{ \"size\": \"%s\", \"query\": { \"bool\": { \"must\": [ %s ] } } }\"\"\" % (query_size,line)\n",
    "    \n",
    "    return complete_query\n",
    "udf_build_exact_queries = F.udf(build_exact_queries, StringType()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_elasticsearch_exact_best_candidate(vars_col, exact_queries_col):\n",
    "    \"\"\"\n",
    "    Let us suppose a column with the following query:\n",
    "    \n",
    "    '{ \"size\": \"50\", \"query\": \n",
    "                    { \"bool\": { \"must\": [ \n",
    "                                {\"match\": {\"name\":\"ROBESPIERRE PITA\"}},\n",
    "                                {\"match\": {\"birthdate\":\"19870505\"}}] } } }'\n",
    "    \n",
    "    so, this function must return a dict with N results like: \n",
    "        {'_index': 'test', '_type': '_doc', '_id': 'aaabbbccc', '_score': 43.9280841,\n",
    "        '_source': {'name': 'ROBESPIERRE PITA', 'birthdate': '19870505', 'other_col': 'other_value'}},\n",
    "    \n",
    "    being N the query_size value set on config, you can see this number on the 'size' field of the query.\n",
    "    \n",
    "    This result can now be used to compute the proper similarity and pick the \n",
    "    best candidate for each record\n",
    "    \"\"\"\n",
    "    from elasticsearch import Elasticsearch\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    es_connect_string = config_['es_connect_string']\n",
    "    es_index_name = config_['es_index_name']\n",
    "    \n",
    "    es = Elasticsearch(es_connect_string)\n",
    "    \n",
    "    candidates = es.search(index=es_index_name, body=exact_queries_col)['hits']['hits']\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(None, None, None)\n",
    "    else:\n",
    "        cols_and_values = get_match_cols_and_values(vars_col, 'general')\n",
    "        best_score_id, best_score_value, scores = find_best_candidates(cols_and_values, candidates)\n",
    "        if best_score_value >= float(config_['cutoff_exact_match']):\n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "        else: \n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(None, None, None)\n",
    "    \n",
    "schema = StructType([StructField(\"best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"sim_best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"similarity_exact_candidates\", StringType(), False)])\n",
    "\n",
    "udf_find_elasticsearch_exact_best_candidate = F.udf(find_elasticsearch_exact_best_candidate, schema)\n",
    "\n",
    "\n",
    "def find_best_candidates(cols_and_values, candidates):\n",
    "    \n",
    "    config_ = config_bc.value\n",
    "    indexed_id_col = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    scores = {}\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        \n",
    "        candidate_id = candidate['_source'][indexed_id_col]\n",
    "        sim_candidate = []\n",
    "        for col_and_value in list(cols_and_values.keys()):\n",
    "            comparison_info = [config_['comparisons'][x] for x in config_['comparisons'] if config_['comparisons'][x]['indexed_col'] == col_and_value][0]\n",
    "            n_comparisons = len(config_['comparisons'].keys())\n",
    "            \n",
    "            sim_for_pair_of_cols = similarity_hub(n_comparisons, comparison_info, cols_and_values[col_and_value], candidate['_source'][col_and_value])\n",
    "                        \n",
    "            sim_candidate.append(sim_for_pair_of_cols)\n",
    "        \n",
    "        score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "        score = (sum(sim_candidate))/score_max\n",
    "        \n",
    "        scores[candidate_id] = score\n",
    "            \n",
    "    best_score_id = max(scores, key=scores.get)\n",
    "    best_score_value = scores[best_score_id]\n",
    "    return best_score_id, best_score_value, scores\n",
    "    \n",
    "    \n",
    "def similarity_hub(n_comparisons, comparison_info, col_and_value, candidate):\n",
    "    \"\"\"\n",
    "    Currently the CIDACS-RL uses overlap for categorical data, jaro_winkler for names and hamming for dates.\n",
    "    \"\"\"\n",
    "    import jellyfish\n",
    "    \n",
    "    # getting relevant information for this pair of values\n",
    "    config_ = config_bc.value\n",
    "#     score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "    similarity = 0.0\n",
    "    weight = float(comparison_info['weight'])\n",
    "    penalty = float(comparison_info['penalty'])\n",
    "    \n",
    "    # first, test if some value are missing\n",
    "    if (candidate == config_['null_value']) or (col_and_value == config_['null_value'])\\\n",
    "        or (candidate == \"\") or (col_and_value == \"\") or (candidate == None) or (col_and_value == None):\n",
    "        similarity = similarity - penalty\n",
    "    else: \n",
    "        sim_type = comparison_info['similarity']\n",
    "        if (sim_type == 'overlap') and(col_and_value == candidate):\n",
    "            similarity += (1.0) * weight\n",
    "            return similarity\n",
    "        elif sim_type == 'jaro_winkler':\n",
    "            similarity += jellyfish.jaro_winkler(col_and_value, candidate) * weight\n",
    "        elif sim_type == 'hamming':\n",
    "            max_size = max(len(col_and_value), len(candidate))\n",
    "            similarity += 1.0 - float(jellyfish.hamming_distance(col_and_value, candidate)/max_size) * weight\n",
    "        else: \n",
    "            print('Please inform valid similarities for cidacs-rl')\n",
    "        \n",
    "        similarity = similarity\n",
    "    return similarity    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading prepocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the auxiliary variables\n",
    "data_ext = config['datasets_info']['indexed_dataset']['extension']\n",
    "data_path = config['datasets_info']['indexed_dataset']['path']\n",
    "\n",
    "# test the extension of the dataset to properly read it\n",
    "if data_ext == 'csv':\n",
    "    indexed_dataset = spark.read.csv(data_path, header=True)\n",
    "elif data_ext == 'parquet':\n",
    "    indexed_dataset = spark.read.parquet(data_path)\n",
    "else:\n",
    "    print(\"Please make sure the extension for this dataset is set as 'csv' or 'parquet'\")\n",
    "    \n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.regexp_replace(F.col('dt_nasc_a'), \"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>sexo_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>YASMIM VITORIA MATIAS FONSECA</td>\n",
       "      <td>TACIANY DOS SANTOS</td>\n",
       "      <td>20071122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>20061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>20071107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_a                              nome_a  \\\n",
       "0           1       YASMIM VITORIA MATIAS FONSECA   \n",
       "1           2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "2           3       FABRICIO RODRIGUES DOS SANTOS   \n",
       "\n",
       "                     nome_mae_a dt_nasc_a  sexo_a  \n",
       "0            TACIANY DOS SANTOS  20071122       2  \n",
       "1  FRANCILEIDE DOS SANTOS ALVES  20061102       1  \n",
       "2      MARCELA MACHADO DA SILVA  20071107       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the auxiliary variables\n",
    "data_ext = config['datasets_info']['tolink_dataset']['extension']\n",
    "data_path = config['datasets_info']['tolink_dataset']['path']\n",
    "\n",
    "# test the extension of the dataset to properly read it\n",
    "if data_ext == 'csv':\n",
    "    tolink_dataset = spark.read.csv(data_path, header=True)\n",
    "elif data_ext == 'parquet':\n",
    "    tolink_dataset = spark.read.parquet(data_path)\n",
    "else:\n",
    "    print(\"Please make sure the extension for this dataset is set as 'csv' or 'parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing tolink dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tolink_dataset.columns:\n",
    "    tolink_dataset = tolink_dataset.withColumn(col, F.col(col).cast('string'))\n",
    "\n",
    "tolink_dataset = tolink_dataset.na.fill(config['null_value'])\n",
    "\n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "tolink_dataset = tolink_dataset.withColumn('dt_nasc_b', F.regexp_replace(F.col('dt_nasc_b'), \"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081</td>\n",
       "      <td>FABIOLA FAGUNDES FRICKS</td>\n",
       "      <td>LUCIMARA COSTA NASCIMENTO</td>\n",
       "      <td>20070816</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4582</td>\n",
       "      <td>ANA KAROLINA RODRIGUES SOUSA</td>\n",
       "      <td>CELINE RAIMUNDA SILVA</td>\n",
       "      <td>20090614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4739</td>\n",
       "      <td>NATALIA DAVID BENTO</td>\n",
       "      <td>KETLEN SANTOS</td>\n",
       "      <td>20091222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                        nome_b                 nome_mae_b  \\\n",
       "0        1081       FABIOLA FAGUNDES FRICKS  LUCIMARA COSTA NASCIMENTO   \n",
       "1        4582  ANA KAROLINA RODRIGUES SOUSA      CELINE RAIMUNDA SILVA   \n",
       "2        4739           NATALIA DAVID BENTO              KETLEN SANTOS   \n",
       "\n",
       "  dt_nasc_b sexo_b  \n",
       "0  20070816      2  \n",
       "1  20090614      2  \n",
       "2  20091222      2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all the cols in data are StringType()\n",
    "\n",
    "for col in indexed_dataset.columns:\n",
    "    indexed_dataset = indexed_dataset.withColumn(col, F.col(col).cast('string'))\n",
    "\n",
    "indexed_dataset = indexed_dataset.na.fill(config['null_value'])\n",
    "    \n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.regexp_replace(F.col('dt_nasc_a'), \"-\", \"\"))\n",
    "\n",
    "# indexing, at last\n",
    "index_df_response = config['index_data']\n",
    "index_name = config['es_index_name']\n",
    "if index_df_response == 'yes':\n",
    "    index_dataframe(indexed_dataset, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# es = Elasticsearch('http://localhost:9200')\n",
    "# content = {\n",
    "#     'size': 1,\n",
    "#     'query': {\n",
    "#         'bool': {\n",
    "#             'must': [\n",
    "#                 {'match': {'dt_nasc_a': '200711asd22'}}\n",
    "#             ]\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# es.search(index=index_name, body=content)['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auxiliary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ = config_bc.value\n",
    "query_size = config_['query_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating vars column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081</td>\n",
       "      <td>FABIOLA FAGUNDES FRICKS</td>\n",
       "      <td>LUCIMARA COSTA NASCIMENTO</td>\n",
       "      <td>20070816</td>\n",
       "      <td>2</td>\n",
       "      <td>[FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4582</td>\n",
       "      <td>ANA KAROLINA RODRIGUES SOUSA</td>\n",
       "      <td>CELINE RAIMUNDA SILVA</td>\n",
       "      <td>20090614</td>\n",
       "      <td>2</td>\n",
       "      <td>[ANA KAROLINA RODRIGUES SOUSA, CELINE RAIMUNDA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                        nome_b                 nome_mae_b  \\\n",
       "0        1081       FABIOLA FAGUNDES FRICKS  LUCIMARA COSTA NASCIMENTO   \n",
       "1        4582  ANA KAROLINA RODRIGUES SOUSA      CELINE RAIMUNDA SILVA   \n",
       "\n",
       "  dt_nasc_b sexo_b                                               vars  \n",
       "0  20070816      2  [FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...  \n",
       "1  20090614      2  [ANA KAROLINA RODRIGUES SOUSA, CELINE RAIMUNDA...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_id_column = config_['datasets_info']['tolink_dataset']['id_column_name']\n",
    "tolink_cols = config_['datasets_info']['tolink_dataset']['columns']\n",
    "tolink_cols = [x for x in tolink_cols if x != tolink_id_column]\n",
    "\n",
    "tolink_dataset = tolink_dataset.withColumn('vars', F.array(tolink_cols))\n",
    "tolink_dataset.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating exact_queries column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081</td>\n",
       "      <td>FABIOLA FAGUNDES FRICKS</td>\n",
       "      <td>LUCIMARA COSTA NASCIMENTO</td>\n",
       "      <td>20070816</td>\n",
       "      <td>2</td>\n",
       "      <td>[FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4582</td>\n",
       "      <td>ANA KAROLINA RODRIGUES SOUSA</td>\n",
       "      <td>CELINE RAIMUNDA SILVA</td>\n",
       "      <td>20090614</td>\n",
       "      <td>2</td>\n",
       "      <td>[ANA KAROLINA RODRIGUES SOUSA, CELINE RAIMUNDA...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4739</td>\n",
       "      <td>NATALIA DAVID BENTO</td>\n",
       "      <td>KETLEN SANTOS</td>\n",
       "      <td>20091222</td>\n",
       "      <td>2</td>\n",
       "      <td>[NATALIA DAVID BENTO, KETLEN SANTOS, 20091222, 2]</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                        nome_b                 nome_mae_b  \\\n",
       "0        1081       FABIOLA FAGUNDES FRICKS  LUCIMARA COSTA NASCIMENTO   \n",
       "1        4582  ANA KAROLINA RODRIGUES SOUSA      CELINE RAIMUNDA SILVA   \n",
       "2        4739           NATALIA DAVID BENTO              KETLEN SANTOS   \n",
       "\n",
       "  dt_nasc_b sexo_b                                               vars  \\\n",
       "0  20070816      2  [FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...   \n",
       "1  20090614      2  [ANA KAROLINA RODRIGUES SOUSA, CELINE RAIMUNDA...   \n",
       "2  20091222      2  [NATALIA DAVID BENTO, KETLEN SANTOS, 20091222, 2]   \n",
       "\n",
       "                                       exact_queries  \n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...  \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...  \n",
       "2  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = tolink_dataset.withColumn('exact_queries', udf_build_exact_queries(F.col('vars')))\n",
    "tolink_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding the best candidate and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "      <th>result_exact_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081</td>\n",
       "      <td>FABIOLA FAGUNDES FRICKS</td>\n",
       "      <td>LUCIMARA COSTA NASCIMENTO</td>\n",
       "      <td>20070816</td>\n",
       "      <td>2</td>\n",
       "      <td>[FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>(1081, 1.0, {842866=0.6373916093300152, 436317...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                   nome_b                 nome_mae_b dt_nasc_b  \\\n",
       "0        1081  FABIOLA FAGUNDES FRICKS  LUCIMARA COSTA NASCIMENTO  20070816   \n",
       "\n",
       "  sexo_b                                               vars  \\\n",
       "0      2  [FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...   \n",
       "\n",
       "                                       exact_queries  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...   \n",
       "\n",
       "                                 result_exact_search  \n",
       "0  (1081, 1.0, {842866=0.6373916093300152, 436317...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = tolink_dataset.withColumn('result_exact_search', F.explode(F.array(udf_find_elasticsearch_exact_best_candidate(F.col('vars'), F.col('exact_queries')))))\n",
    "tolink_dataset.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "      <th>result_exact_search</th>\n",
       "      <th>best_score_id_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081</td>\n",
       "      <td>FABIOLA FAGUNDES FRICKS</td>\n",
       "      <td>LUCIMARA COSTA NASCIMENTO</td>\n",
       "      <td>20070816</td>\n",
       "      <td>2</td>\n",
       "      <td>[FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>(1081, 1.0, {842866=0.6373916093300152, 436317...</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                   nome_b                 nome_mae_b dt_nasc_b  \\\n",
       "0        1081  FABIOLA FAGUNDES FRICKS  LUCIMARA COSTA NASCIMENTO  20070816   \n",
       "\n",
       "  sexo_b                                               vars  \\\n",
       "0      2  [FABIOLA FAGUNDES FRICKS, LUCIMARA COSTA NASCI...   \n",
       "\n",
       "                                       exact_queries  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...   \n",
       "\n",
       "                                 result_exact_search best_score_id_exact_match  \n",
       "0  (1081, 1.0, {842866=0.6373916093300152, 436317...                      1081  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = tolink_dataset.withColumn('best_candidate_exact', tolink_dataset.result_exact_search['best_candidate_exact'])\n",
    "tolink_dataset = tolink_dataset.withColumn('sim_best_candidate_exact', tolink_dataset.result_exact_search['sim_best_candidate_exact'])\n",
    "tolink_dataset = tolink_dataset.withColumn('similarity_exact_candidates', tolink_dataset.result_exact_search['best_candidate_exact'])\n",
    "\n",
    "cols_to_drop = ['result_exact_search']\n",
    "tolink_dataset = tolink_dataset.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_cidacs_b: string (nullable = false)\n",
      " |-- nome_b: string (nullable = false)\n",
      " |-- nome_mae_b: string (nullable = false)\n",
      " |-- dt_nasc_b: string (nullable = false)\n",
      " |-- sexo_b: string (nullable = false)\n",
      " |-- vars: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- exact_queries: string (nullable = true)\n",
      " |-- result_exact_search: struct (nullable = true)\n",
      " |    |-- best_candidate_exact: string (nullable = false)\n",
      " |    |-- sim_best_candidate_exact: string (nullable = false)\n",
      " |    |-- similarity_exact_candidates: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolink_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_id, best_score_value, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.explode(F.array(udf_best_candidate_search(F.col('vars'), F.col('queries'), F.lit(es_index_name), F.lit(es_connect_string), F.lit('most_distant'), F.lit(True)))))\n",
    "def find_elasticsearch_exact_best_candidate(vars_col, exact_queries_col):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolink_dataset.limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'udf_find_cidacs_rl_exact_candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b0a14a9f0790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtolink_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type_col'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf_find_cidacs_rl_exact_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'es_exact_cand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type_col'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'udf_find_cidacs_rl_exact_candidates' is not defined"
     ]
    }
   ],
   "source": [
    "tolink_dataset.limit(4).withColumn('type_col', udf_find_cidacs_rl_exact_candidates(F.col('es_exact_cand'))).select('type_col').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexed_col': 'nome_a', 'tolink_col': 'nome_b', 'must_match': 'true', 'should_match': 'true', 'is_fuzzy': 'true', 'boost': '3.0', 'query_type': 'match', 'similarity': 'jaro_wikler', 'weight': 1.0, 'penalty': 0.02}\n",
      "{'indexed_col': 'nome_mae_a', 'tolink_col': 'nome_mae_b', 'must_match': 'true', 'should_match': 'true', 'is_fuzzy': 'true', 'boost': '2.0', 'query_type': 'match', 'similarity': 'jaro_wikler', 'weight': 1.0, 'penalty': 0.02}\n",
      "{'indexed_col': 'dt_nasc_a', 'tolink_col': 'dt_nasc_b', 'must_match': 'false', 'should_match': 'true', 'is_fuzzy': 'false', 'boost': '', 'query_type': 'term', 'similarity': 'hamming', 'weight': 1.0, 'penalty': 0.02}\n",
      "{'indexed_col': 'sexo_a', 'tolink_col': 'sexo_b', 'must_match': 'true', 'should_match': 'true', 'is_fuzzy': 'false', 'boost': '', 'query_type': 'term', 'similarity': 'overlap', 'weight': 1.0, 'penalty': 0.02}\n"
     ]
    }
   ],
   "source": [
    "for info_comp in config['comparisons']:\n",
    "    print(config['comparisons'][info_comp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cidacs_rl_exact_candidates(es_exact_cand_col):\n",
    "    import ast\n",
    "    return type(ast.literal_eval(es_exact_cand_col))\n",
    "udf_find_cidacs_rl_exact_candidates = F.udf(find_cidacs_rl_exact_candidates, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [{'_type':'_doc', '_source':{'dt_nasc_a':'20070816', 'id_cidacs_a':'1081', 'nome_mae_a':'LUCIMARA COSTA NASCIMENTO', 'sexo_a':'2', 'nome_a':'FABIOLA FAGUNDES FRICKS'}, '_id':'ckz6TX4BggJoL2NZaXO6', '_index':'fd-cidacs-rl', '_score':'43.248585'}, \n",
    "                 {'_type':'_doc', '_source':{'dt_nasc_a':'20100709', 'id_cidacs_a':'339811', 'nome_mae_a':'ADRIANA FERNANDES COSTA', 'sexo_a':'2', 'nome_a':'FABIOLA FAGUNDES FRICKS'}, '_id':'wFD6TX4BggJoL2NZjO9i', '_index':'fd-cidacs-rl', '_score':'32.082012'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_col = ['FABIOLA FAGUNDES FRICKS', 'LUCIMARA COSTA NASCIMENTO', '20070816', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_a': 'FABIOLA FAGUNDES FRICKS',\n",
       " 'nome_mae_a': 'LUCIMARA COSTA NASCIMENTO',\n",
       " 'dt_nasc_a': '20070816',\n",
       " 'sexo_a': '2'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_and_values = get_match_cols_and_values(vars_col, 'general')\n",
    "cols_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FABIOLA FAGUNDES FRICKS'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_and_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FABIOLA FAGUNDES FRICKS\n",
      "FABIOLA FAGUNDES FRICKS\n"
     ]
    }
   ],
   "source": [
    "candidate = candidates[0]['_source']['nome_a']\n",
    "col_and_value = cols_and_values['nome_a']\n",
    "print(cadidate)\n",
    "print(col_and_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ = config_bc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comparisons = len(config_['comparisons'].keys())\n",
    "n_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexed_col': 'nome_a',\n",
       " 'tolink_col': 'nome_b',\n",
       " 'must_match': 'true',\n",
       " 'should_match': 'true',\n",
       " 'is_fuzzy': 'true',\n",
       " 'boost': '3.0',\n",
       " 'query_type': 'match',\n",
       " 'similarity': 'jaro_winkler',\n",
       " 'weight': 1.0,\n",
       " 'penalty': 0.02}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_info = [config_['comparisons'][x] for x in config_['comparisons'] if config_['comparisons'][x]['indexed_col'] == 'nome_a'][0]\n",
    "comparison_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_hub(n_comparisons, comparison_info, col_and_value, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_id, best_score_value, scores = find_best_candidates(cols_and_values, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1081'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1081': 1.0, '339811': 0.751929347826087}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_candidates(cols_and_values, candidates):\n",
    "    \n",
    "    config_ = config_bc.value\n",
    "    indexed_id_col = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    scores = {}\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        \n",
    "        candidate_id = candidate['_source'][indexed_id_col]\n",
    "        sim_candidate = []\n",
    "        for col_and_value in list(cols_and_values.keys()):\n",
    "            comparison_info = [config_['comparisons'][x] for x in config_['comparisons'] if config_['comparisons'][x]['indexed_col'] == col_and_value][0]\n",
    "            n_comparisons = len(config_['comparisons'].keys())\n",
    "            \n",
    "            sim_for_pair_of_cols = similarity_hub(n_comparisons, comparison_info, cols_and_values[col_and_value], candidate['_source'][col_and_value])\n",
    "                        \n",
    "            sim_candidate.append(sim_for_pair_of_cols)\n",
    "        \n",
    "        score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "        score = (sum(sim_candidate))/score_max\n",
    "        \n",
    "        scores[candidate_id] = score\n",
    "            \n",
    "    best_score_id = max(scores, key=scores.get)\n",
    "    best_score_value = scores[best_score_id]\n",
    "    return best_score_id, best_score_value, scores\n",
    "    \n",
    "    \n",
    "def similarity_hub(n_comparisons, comparison_info, col_and_value, candidate):\n",
    "    \"\"\"\n",
    "    Currently the CIDACS-RL uses overlap for categorical data, jaro_winkler for names and hamming for dates.\n",
    "    \"\"\"\n",
    "    import jellyfish\n",
    "    \n",
    "    # getting relevant information for this pair of values\n",
    "    config_ = config_bc.value\n",
    "#     score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "    similarity = 0.0\n",
    "    weight = float(comparison_info['weight'])\n",
    "    penalty = float(comparison_info['penalty'])\n",
    "    \n",
    "    # first, test if some value are missing\n",
    "    if (candidate == config_['null_value']) or (col_and_value == config_['null_value'])\\\n",
    "        or (candidate == \"\") or (col_and_value == \"\") or (candidate == None) or (col_and_value == None):\n",
    "        similarity = similarity - penalty\n",
    "    else: \n",
    "        sim_type = comparison_info['similarity']\n",
    "        if (sim_type == 'overlap') and(col_and_value == candidate):\n",
    "            similarity += (1.0) * weight\n",
    "            return similarity\n",
    "        elif sim_type == 'jaro_winkler':\n",
    "            similarity += jellyfish.jaro_winkler(col_and_value, candidate) * weight\n",
    "        elif sim_type == 'hamming':\n",
    "            max_size = max(len(col_and_value), len(candidate))\n",
    "            similarity += 1.0 - float(jellyfish.hamming_distance(col_and_value, candidate)/max_size) * weight\n",
    "        else: \n",
    "            print('Please inform valid similarities for cidacs-rl')\n",
    "        \n",
    "        similarity = similarity\n",
    "    return similarity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elasticsearch_exact_best_candidate(vars_col, exact_queries_col):\n",
    "    \"\"\"\n",
    "    Let us suppose a column with the following query:\n",
    "    \n",
    "    '{ \"size\": \"50\", \"query\": \n",
    "                    { \"bool\": { \"must\": [ \n",
    "                                {\"match\": {\"name\":\"ROBESPIERRE PITA\"}},\n",
    "                                {\"match\": {\"birthdate\":\"19870505\"}}] } } }'\n",
    "    \n",
    "    so, this function must return a dict with N results like: \n",
    "        {'_index': 'test', '_type': '_doc', '_id': 'aaabbbccc', '_score': 43.9280841,\n",
    "        '_source': {'name': 'ROBESPIERRE PITA', 'birthdate': '19870505', 'other_col': 'other_value'}},\n",
    "    \n",
    "    being N the query_size value set on config, you can see this number on the 'size' field of the query.\n",
    "    \n",
    "    This result can now be used to compute the proper similarity and pick the \n",
    "    best candidate for each record\n",
    "    \"\"\"\n",
    "    from elasticsearch import Elasticsearch\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    es_connect_string = config_['es_connect_string']\n",
    "    es_index_name = config_['es_index_name']\n",
    "    \n",
    "    es = Elasticsearch(es_connect_string)\n",
    "    \n",
    "    candidates = es.search(index=es_index_name, body=exact_queries_col)['hits']['hits']\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(None, None, None)\n",
    "    else:\n",
    "        cols_and_values = get_match_cols_and_values(vars_col, 'general')\n",
    "        best_score_id, best_score_value, scores = find_best_candidates(cols_and_values, candidates)\n",
    "        if best_score_value >= float(config_['cutoff_exact_match']):\n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "        else: \n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(None, None, None)\n",
    "    \n",
    "schema = StructType([StructField(\"best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"sim_best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"similarity_exact_candidates\", StringType(), False)])\n",
    "\n",
    "udf_find_elasticsearch_exact_best_candidate = F.udf(find_elasticsearch_exact_best_candidate, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_exact_match_vars = [config_['comparisons'][x]['indexed_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolink_cols_dict = dict(zip(indexed_cols, list_values))\n",
    "tolink_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_col = ['FABIOLA FAGUNDES FRICKS', 'LUCIMARA COSTA NASCIMENTO', '2007-08-16', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_match_cols(vars_col):\n",
    "    indexed_id_column = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    tolink_id_column = config_['datasets_info']['tolink_dataset']['id_column_name']\n",
    "\n",
    "    indexed_cols = config_['datasets_info']['indexed_dataset']['columns']\n",
    "    indexed_cols = [x for x in indexed_cols if x != indexed_id_column]\n",
    "\n",
    "    tolink_cols_dict = dict(zip(indexed_cols, vars_col))\n",
    "\n",
    "    indexed_exact_match_vars = [config_['comparisons'][x]['indexed_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']\n",
    "\n",
    "    non_exact_match_cols = list(set(indexed_cols) - set(indexed_exact_match_vars))\n",
    "    [tolink_cols_dict.pop(x, None) for x in non_exact_match_cols]\n",
    "    \n",
    "    return tolink_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_a': 'FABIOLA FAGUNDES FRICKS',\n",
       " 'nome_mae_a': 'LUCIMARA COSTA NASCIMENTO',\n",
       " 'sexo_a': '2'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_exact_match_cols(vars_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nome_a', 'nome_mae_a', 'dt_nasc_a', 'sexo_a']\n",
      "['nome_b', 'nome_mae_b', 'dt_nasc_b', 'sexo_b']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "indexed_id_column = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "tolink_id_column = config_['datasets_info']['tolink_dataset']['id_column_name']\n",
    "\n",
    "indexed_cols = config_['datasets_info']['indexed_dataset']['columns']\n",
    "indexed_cols = [x for x in indexed_cols if x != indexed_id_column]\n",
    "print(indexed_cols)\n",
    "\n",
    "tolink_cols = config_['datasets_info']['tolink_dataset']['columns']\n",
    "tolink_cols = [x for x in tolink_cols if x != tolink_id_column]\n",
    "print(tolink_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_values = ['FABIOLA FAGUNDES FRICKS', 'LUCIMARA COSTA NASCIMENTO', '2007-08-16', 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_a': 'FABIOLA FAGUNDES FRICKS',\n",
       " 'nome_mae_a': 'LUCIMARA COSTA NASCIMENTO',\n",
       " 'dt_nasc_a': '2007-08-16',\n",
       " 'sexo_a': 2}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that we are linking indexed keys with tolink values\n",
    "tolink_cols_dict = dict(zip(indexed_cols, list_values))\n",
    "tolink_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nome_a', 'nome_mae_a', 'sexo_a']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_exact_match_vars = [config_['comparisons'][x]['indexed_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']\n",
    "indexed_exact_match_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolink_exact_match_vars = [config_['comparisons'][x]['tolink_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']\n",
    "# exact_match_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_a': 'FABIOLA FAGUNDES FRICKS',\n",
       " 'nome_mae_a': 'LUCIMARA COSTA NASCIMENTO',\n",
       " 'sexo_a': 2}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_exact_match_cols = list(set(indexed_cols) - set(indexed_exact_match_vars))\n",
    "[tolink_cols_dict.pop(x, None) for x in non_exact_match_cols]\n",
    "tolink_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "query_size = config_['query_size']\n",
    "print(type(query_size))\n",
    "print(query_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_ = \"\"\"{\"match\": {\"\"\"\n",
    "suffix_ = \"\"\"}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"match\": {\"nome_a\":\"FABIOLA FAGUNDES FRICKS\"}}\n",
      "{\"match\": {\"nome_mae_a\":\"LUCIMARA COSTA NASCIMENTO\"}}\n",
      "{\"match\": {\"sexo_a\":\"2\"}}\n"
     ]
    }
   ],
   "source": [
    "strings = []\n",
    "for col in list(tolink_cols_dict.keys()):\n",
    "    string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \"\\\"\" +  str(tolink_cols_dict[col]) + \"\\\"\" + str(suffix_)\n",
    "    print(string)\n",
    "    strings.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"match\": {\"nome_a\":\"FABIOLA FAGUNDES FRICKS\"}},{\"match\": {\"nome_mae_a\":\"LUCIMARA COSTA NASCIMENTO\"}},{\"match\": {\"sexo_a\":\"2\"}}'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = ','.join(strings)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"size\": \"50\", \"query\": { \"bool\": { \"should\": [ {\"match\": {\"nome_a\":\"FABIOLA FAGUNDES FRICKS\"}},{\"match\": {\"nome_mae_a\":\"LUCIMARA COSTA NASCIMENTO\"}},{\"match\": {\"sexo_a\":\"2\"}} ] } } }'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_query = \"\"\"{ \"size\": \"%s\", \"query\": { \"bool\": { \"must\": [ %s ] } } }\"\"\" % (query_size,line)\n",
    "complete_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete\n",
    "tolink_cols_dict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "        'size': 5,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'lb_sex': sex}},\n",
    "                    {'match': {'lb_birthday_child': birthday_child}},\n",
    "                    {'match': {'lb_addr_residence': addr_residence}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {\n",
    "        'size': 5,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'lb_sex': {'query': sex, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'lb_addr_residence': {'query': addr_residence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'4.0'}}},\n",
    "                    {'match': {'lb_addr_occurrence': {'query': addr_occurrence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'0.5'}}},\n",
    "                    {'match': {'lb_state_residence': {'query': state_residence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'1.0'}}},\n",
    "                    {'match': {'lb_state_occurrence': {'query': state_occurrence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'0.5'}}},\n",
    "                    {'match': {'lb_state_mun_residence': {'query': state_mun_residence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'lb_state_mun_occurrence': {'query': state_mun_occurrence, 'fuzziness':'AUTO', 'operator':'or', 'boost':'0.5'}}},\n",
    "                    {'match': {'lb_day_birth': {'query': day_birth}}},\n",
    "                    {'match': {'lb_month_birth': {'query': month_birth}}},\n",
    "                    {'match': {'lb_year_birth': {'query': year_birth}}},\n",
    "                    {'match': {'lb_mun_residence_pad': {'query': mun_residence_pad}}},\n",
    "                    {'match': {'lb_loc_residence_pad': {'query': loc_residence_pad}}},\n",
    "                    {'match': {'lb_mun_occurrence_pad': {'query': mun_occurrence_pad}}},\n",
    "                    {'match': {'lb_loc_occurrence_pad': {'query': loc_occurrence_pad}}},\n",
    "                    {'term': {'lb_birthday_child': birthday_child}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome_a': {'compare_to': 'nome_b',\n",
       "  'must_match': 'true',\n",
       "  'should_match': 'true',\n",
       "  'is_fuzzy': 'true',\n",
       "  'boost': '3.0',\n",
       "  'query_type': 'match',\n",
       "  'similarity': 'jaro_wikler',\n",
       "  'weight': 1.0,\n",
       "  'penalty': 0.02},\n",
       " 'nome_mae_a': {'compare_to': 'nome_mae_b',\n",
       "  'must_match': 'true',\n",
       "  'should_match': 'true',\n",
       "  'is_fuzzy': 'true',\n",
       "  'boost': '2.0',\n",
       "  'query_type': 'match',\n",
       "  'similarity': 'jaro_wikler',\n",
       "  'weight': 1.0,\n",
       "  'penalty': 0.02},\n",
       " 'dt_nasc_a': {'compare_to': 'dt_nasc_b',\n",
       "  'must_match': 'false',\n",
       "  'should_match': 'true',\n",
       "  'is_fuzzy': 'false',\n",
       "  'boost': '',\n",
       "  'query_type': 'term',\n",
       "  'similarity': 'hamming',\n",
       "  'weight': 1.0,\n",
       "  'penalty': 0.02},\n",
       " 'sexo_a': {'compare_to': 'sexo_b',\n",
       "  'must_match': 'true',\n",
       "  'should_match': 'true',\n",
       "  'is_fuzzy': 'false',\n",
       "  'boost': '',\n",
       "  'query_type': 'term',\n",
       "  'similarity': 'overlap',\n",
       "  'weight': 1.0,\n",
       "  'penalty': 0.02}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['comparisons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_queries(list_of_values_col, query_size):\n",
    "    \"\"\"\n",
    "    Let us suppose the following column values:\n",
    "    list_of_cols = ['ab', 'vbx']\n",
    "    list_of_values = ['2', 'mamao']\n",
    "    so, this udf must return a column with values like this: \n",
    "    {\"match\": {\"ab\":\"2\"}},{\"match\": {\"vbx\":\"mamao\"}}\n",
    "    \"\"\"\n",
    "    query_size = str(query_size)\n",
    "    list_of_cols = cols.value  # [x for x in cols.value if x != 'id']\n",
    "    prefix_ = \"\"\"{\"match\": {\"\"\"\n",
    "    suffix_ = \"\"\"}}\"\"\"\n",
    "    strings = []\n",
    "    dict_cols = dict(zip(list_of_cols, list_of_values_col))\n",
    "    \n",
    "    for col in list(dict_cols.keys()):\n",
    "        string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \"\\\"\" +  str(dict_cols[col]) + \"\\\"\" + str(suffix_)\n",
    "        strings.append(string)\n",
    "    \n",
    "    line = ','.join(strings)\n",
    "    complete_query = \"\"\"{ \"size\": \"%s\", \"query\": { \"bool\": { \"should\": [ %s ] } } }\"\"\" % (query_size,line)\n",
    "    return complete_query\n",
    "udf_build_queries = F.udf(build_queries, StringType()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
