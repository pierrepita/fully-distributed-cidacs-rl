{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_data': 'yes',\n",
       " 'es_index_name': 'fd-cidacs-rl',\n",
       " 'es_connect_string': 'http://localhost:9200',\n",
       " 'query_size': 50,\n",
       " 'cutoff_exact_match': '0.95',\n",
       " 'null_value': '99',\n",
       " 'temp_dir': '../0_global_data/fd-cidacs-rl/temp_dataframe/',\n",
       " 'debug': 'false',\n",
       " 'datasets_info': {'indexed_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-dataset-A.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_a', 'nome_a', 'nome_mae_a', 'dt_nasc_a', 'sexo_a'],\n",
       "   'id_column_name': 'id_cidacs_a'},\n",
       "  'tolink_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-datasets-b/sinthetic-datasets-b-1000.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_b', 'nome_b', 'nome_mae_b', 'dt_nasc_b', 'sexo_b'],\n",
       "   'id_column_name': 'id_cidacs_b'},\n",
       "  'result_dataset': {'path': '../0_global_data/result/'}},\n",
       " 'comparisons': {'name': {'indexed_col': 'nome_a',\n",
       "   'tolink_col': 'nome_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '3.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 5.0,\n",
       "   'penalty': 0.02},\n",
       "  'mothers_name': {'indexed_col': 'nome_mae_a',\n",
       "   'tolink_col': 'nome_mae_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '2.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 5.0,\n",
       "   'penalty': 0.02},\n",
       "  'birthdate': {'indexed_col': 'dt_nasc_a',\n",
       "   'tolink_col': 'dt_nasc_b',\n",
       "   'must_match': 'false',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'hamming',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02},\n",
       "  'sex': {'indexed_col': 'sexo_a',\n",
       "   'tolink_col': 'sexo_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'overlap',\n",
       "   'weight': 3.0,\n",
       "   'penalty': 0.02}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('config.txt')\n",
    "config = json.load(f)\n",
    "config_bc = sc.broadcast(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_match_cols_and_values(vars_col, query_type, add_id_col):\n",
    "    \"\"\"\n",
    "    query_type must be 'exact' for building exact queries or 'general' for any else query and comparison.\n",
    "    \"\"\"\n",
    "    config_ = config_bc.value\n",
    "    # getting names of indexed columns\n",
    "    indexed_id_column = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    \n",
    "    indexed_cols = config_['datasets_info']['indexed_dataset']['columns']\n",
    "    \n",
    "#     if query_type == 'general':\n",
    "#         indexed_cols = [x for x in indexed_cols if x != indexed_id_column]\n",
    "        \n",
    "    # notice that we are linking indexed keys with tolink values\n",
    "    # the keys will be used to set which field will be fetched on es\n",
    "    # the values will be used as search content\n",
    "    tolink_cols_dict = dict(zip(indexed_cols, vars_col))\n",
    "    \n",
    "    if add_id_col == False:\n",
    "        tolink_cols_dict.pop(indexed_id_column, None)\n",
    "    \n",
    "    if query_type == 'general':\n",
    "        return tolink_cols_dict\n",
    "    elif query_type == 'exact':\n",
    "        # finding which are the columns used on exact match step\n",
    "        indexed_exact_match_vars = [indexed_id_column] + [config_['comparisons'][x]['indexed_col'] for x in config_['comparisons'] if config_['comparisons'][x]['must_match'] == 'true']\n",
    "        non_exact_match_cols = list(set(indexed_cols) - set(indexed_exact_match_vars))\n",
    "        # deleting those columns of non-exact match\n",
    "        [tolink_cols_dict.pop(x, None) for x in non_exact_match_cols]\n",
    "        \n",
    "        return tolink_cols_dict\n",
    "    else: \n",
    "        print(\"Please use 'general' or 'exact' as query_type input\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def index_dataframe(dataframe, es_index_name):\n",
    "    # creating new index\n",
    "    dataframe.write.format(\"org.elasticsearch.spark.sql\") \\\n",
    "                 .option(\"es.resource\", es_index_name).mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_exact_queries(vars_col): \n",
    "    \"\"\"\n",
    "    Let us suppose the following values:\n",
    "    vars_col = ['ROBESPIERRE PITA', '1987-05-05', '1', 'Mari Santos']\n",
    "    indexed_cols = ['name', 'birthdate', 'sex', 'mothers_name']\n",
    "    query_size = 10\n",
    "    \n",
    "    and only the first two attributes are assigned to exact match.\n",
    "    So, the resulting query column would be: \n",
    "    '{ \"size\": \"50\", \"query\": \n",
    "                    { \"bool\": { \"must\": [ \n",
    "                                {\"match\": {\"name\":\"ROBESPIERRE PITA\"}},\n",
    "                                {\"match\": {\"birthdate\":\"19870505\"}}] } } }'\n",
    "    Requirements: \n",
    "    - All values on vars_col must be converted into string\n",
    "    - All the hyphens symbols must be taken from date type used to search (e.g. 1987-05-05 must be converted to 19870505)\n",
    "    - The config json must be available as a broadcast through sc.broadcast() function.\n",
    "    - The names of indexed columns must be correctly filled. \n",
    "    \"\"\"\n",
    "    config_ = config_bc.value\n",
    "    query_size = config_['query_size']\n",
    "    \n",
    "    tolink_cols_dict = get_match_cols_and_values(vars_col, 'exact', False)\n",
    "    \n",
    "    # -------------------------------------------- #\n",
    "    #   starting the building of query string      #\n",
    "    # -------------------------------------------- #\n",
    "    # setting the preffix and suffix of query core\n",
    "    prefix_ = \"\"\"{\"match\": {\"\"\"\n",
    "    suffix_ = \"\"\"}}\"\"\"\n",
    "    \n",
    "    # filling the query core with all indexed columns and values from vars_col\n",
    "    strings = []\n",
    "    for col in list(tolink_cols_dict.keys()):\n",
    "        string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \"\\\"\" +  str(tolink_cols_dict[col]) + \"\\\"\" + str(suffix_)\n",
    "        strings.append(string)\n",
    "    \n",
    "    # building the query core. \n",
    "    # Should be like: {\"match\": {\"name\":\"ROBESPIERRE PITA\"}}, {\"birthdate\": {\"name\":\"1987-05-05\"}}\n",
    "    line = ','.join(strings)\n",
    "    \n",
    "    # Finally the final query string\n",
    "    complete_query = \"\"\"{ \"size\": \"%s\", \"query\": { \"bool\": { \"must\": [ %s ] } } }\"\"\" % (query_size,line)\n",
    "    \n",
    "    return complete_query\n",
    "udf_build_exact_queries = F.udf(build_exact_queries, StringType()) \n",
    "\n",
    "def build_non_exact_queries(vars_col): \n",
    "    \"\"\"\n",
    "    Let us suppose the following values:\n",
    "    vars_col = ['ROBESPIERRE PITA', '1987-05-05', '1', 'Mari Santos']\n",
    "    indexed_cols = ['name', 'birthdate', 'sex', 'mothers_name']\n",
    "    query_size = 10\n",
    "    \n",
    "    and only the first two attributes are assigned to exact match.\n",
    "    So, the resulting query column would be: \n",
    "    '{ \"size\": \"50\", \n",
    "         \"query\": { \n",
    "             \"bool\": { \n",
    "                 \"should\": [ \n",
    "                     {'match': {'nome_a': {'query': 'ROBESPIERRE PITA', 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                     {\"match\": {\"birthdate\":\"19870505\"}} ] } } }\n",
    "                     {\"term\": {\"sexo_a\":\"1\"}} ] } } }'\n",
    "    Requirements: \n",
    "    - All values on vars_col must be converted into string\n",
    "    - All the hyphens symbols must be taken from date type used to search (e.g. 1987-05-05 must be converted to 19870505)\n",
    "    - The config json must be available as a broadcast through sc.broadcast() function.\n",
    "    - The names of indexed columns must be correctly filled. \n",
    "    \"\"\"\n",
    "    config_ = config_bc.value\n",
    "    query_size = config_['query_size']\n",
    "    \n",
    "    tolink_cols_dict = get_match_cols_and_values(vars_col, 'exact', False)\n",
    "    \n",
    "    # -------------------------------------------- #\n",
    "    #   starting the building of query string      #\n",
    "    # -------------------------------------------- #\n",
    "    \n",
    "    # filling the query core with all indexed columns and values from vars_col\n",
    "    comparisons = [config['comparisons'][x] for x in config['comparisons']]\n",
    "    strings = []\n",
    "    for col in list(tolink_cols_dict.keys()):\n",
    "        query_col_instructions = [x for x in comparisons if x['indexed_col'] == col][0]\n",
    "        print(col)\n",
    "        query_type = str(query_col_instructions['query_type'])\n",
    "        prefix_ = \"\"\"{\"%s\": {\"\"\" % query_type\n",
    "        suffix_ = \"\"\"}}\"\"\"\n",
    "\n",
    "        if query_col_instructions['should_match'] == 'true':\n",
    "            if query_col_instructions['is_fuzzy'] == 'true':\n",
    "                boost = str(query_col_instructions['boost'])\n",
    "                string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \" { \\\"query\\\" : \\\"\" +  str(tolink_cols_dict[col]) + \"\\\"\" + \", \\\"fuzziness\\\":\\\"AUTO\\\", \\\"operator\\\":\\\"or\\\", \\\"boost\\\":\\\"\" + boost + \"\\\" }\" + str(suffix_)\n",
    "                \n",
    "            if query_col_instructions['is_fuzzy'] == 'false':\n",
    "                string = str(prefix_) + \"\\\"\" + str(col) + \"\\\"\" + \":\" + \"\\\"\" +  str(tolink_cols_dict[col]) + \"\\\"\" + str(suffix_)\n",
    "        strings.append(string)\n",
    "    \n",
    "    # building the query core. \n",
    "    # is_fuzzy = 'true' should be like: {\"match\": {\"name\":\"ROBESPIERRE PITA\", \"fuzziness\":\"AUTO\", \"operator\":\"or\", \"boost\":\"3.0\"}}, {\"term\": {\"dt_nasc_a\":\"20070816\"}}\n",
    "    line = ','.join(strings)\n",
    "    \n",
    "    # Finally the final query string\n",
    "    complete_query = \"\"\"{ \"size\": \"%s\", \"query\": { \"bool\": { \"should\": [ %s ] } } }\"\"\" % (query_size,line)\n",
    "    \n",
    "    return complete_query\n",
    "udf_build_non_exact_queries = F.udf(build_non_exact_queries, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_elasticsearch_exact_best_candidate(vars_col, exact_queries_col):\n",
    "    \"\"\"\n",
    "    Let us suppose a column with the following query:\n",
    "    \n",
    "    '{ \"size\": \"50\", \"query\": \n",
    "                    { \"bool\": { \"must\": [ \n",
    "                                {\"match\": {\"name\":\"ROBESPIERRE PITA\"}},\n",
    "                                {\"match\": {\"birthdate\":\"19870505\"}}] } } }'\n",
    "    \n",
    "    so, this function must return a dict with N results like: \n",
    "        {'_index': 'test', '_type': '_doc', '_id': 'aaabbbccc', '_score': 43.9280841,\n",
    "        '_source': {'name': 'ROBESPIERRE PITA', 'birthdate': '19870505', 'other_col': 'other_value'}},\n",
    "    \n",
    "    being N the query_size value set on config, you can see this number on the 'size' field of the query.\n",
    "    \n",
    "    This result can now be used to compute the proper similarity and pick the \n",
    "    best candidate for each record\n",
    "    \"\"\"\n",
    "    from elasticsearch import Elasticsearch\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    es_connect_string = config_['es_connect_string']\n",
    "    es_index_name = config_['es_index_name']\n",
    "    \n",
    "    es = Elasticsearch(es_connect_string)\n",
    "    \n",
    "    candidates = es.search(index=es_index_name, body=exact_queries_col)['hits']['hits']\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        best_score_id, best_score_value, scores = 'null', 'null', 'null'\n",
    "        return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "    else:\n",
    "        cols_and_values = get_match_cols_and_values(vars_col, 'general', True)\n",
    "        best_score_id, best_score_value, scores = find_best_candidates(cols_and_values, candidates)\n",
    "\n",
    "        if float(best_score_value) >= float(config_['cutoff_exact_match']):\n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "        else: \n",
    "            best_score_id, best_score_value, scores = 'null', 'null', 'null'\n",
    "            return T.Row('best_candidate_exact', 'sim_best_candidate_exact', 'similarity_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "\n",
    "schema = StructType([StructField(\"best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"sim_best_candidate_exact\", StringType(), False), \n",
    "                     StructField(\"similarity_exact_candidates\", StringType(), False)])\n",
    "udf_find_elasticsearch_exact_best_candidate = F.udf(find_elasticsearch_exact_best_candidate, schema)\n",
    "\n",
    "\n",
    "def find_elasticsearch_non_exact_best_candidate(vars_col, non_exact_queries_col):\n",
    "    \"\"\"\n",
    "    Let us suppose a column with the following query:\n",
    "    \n",
    "    '{ \"size\": \"50\", \n",
    "         \"query\": { \n",
    "             \"bool\": { \n",
    "                 \"should\": [ \n",
    "                     {\"match\": {\"nome_a\":\"ROBESPIERRE PITA\", \"fuzziness\":\"AUTO\", \"operator\":\"or\", \"boost\":\"3.0\"}},\n",
    "                     {\"match\": {\"birthdate\":\"19870505\"}} ] } } }\n",
    "                     {\"term\": {\"sexo_a\":\"1\"}} ] } } }'\n",
    "    \n",
    "    so, this function must return a dict with N results like: \n",
    "        {'_index': 'test', '_type': '_doc', '_id': 'aaabbbccc', '_score': 43.9280841,\n",
    "        '_source': {'name': 'ROBESPIERRE PITA', 'birthdate': '19870505', 'other_col': 'other_value'}},\n",
    "    \n",
    "    being N the query_size value set on config, you can see this number on the 'size' field of the query.\n",
    "    \n",
    "    This result can now be used to compute the proper similarity and pick the \n",
    "    best candidate for each record\n",
    "    \"\"\"\n",
    "    from elasticsearch import Elasticsearch\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    es_connect_string = config_['es_connect_string']\n",
    "    es_index_name = config_['es_index_name']\n",
    "    \n",
    "    es = Elasticsearch(es_connect_string)\n",
    "    \n",
    "    candidates = es.search(index=es_index_name, body=non_exact_queries_col)['hits']['hits']\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        best_score_id, best_score_value, scores = 'null', 'null', 'null'\n",
    "        return T.Row('best_candidate_non_exact', 'sim_best_candidate_non_exact', 'similarity_non_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "    else:\n",
    "        cols_and_values = get_match_cols_and_values(vars_col, 'general', True)\n",
    "        best_score_id, best_score_value, scores = find_best_candidates(cols_and_values, candidates)\n",
    "        return T.Row('best_candidate_non_exact', 'sim_best_candidate_non_exact', 'similarity_non_exact_candidates')(best_score_id, best_score_value, scores)\n",
    "        \n",
    "schema = StructType([StructField(\"best_candidate_non_exact\", StringType(), False), \n",
    "                     StructField(\"sim_best_candidate_non_exact\", StringType(), False), \n",
    "                     StructField(\"similarity_non_exact_candidates\", StringType(), False)])\n",
    "udf_find_elasticsearch_non_exact_best_candidate = F.udf(find_elasticsearch_non_exact_best_candidate, schema)\n",
    "\n",
    "\n",
    "\n",
    "def find_best_candidates(cols_and_values, candidates):\n",
    "    \n",
    "    config_ = config_bc.value\n",
    "    indexed_id_col = config_['datasets_info']['indexed_dataset']['id_column_name']\n",
    "    id_value = cols_and_values[indexed_id_col]\n",
    "    scores = {}\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        candidate_id = candidate['_source'][indexed_id_col]\n",
    "        sim_candidate = []\n",
    "\n",
    "        for col_and_value in list(cols_and_values.keys()):\n",
    "            if col_and_value != indexed_id_col:\n",
    "                comparison_info = [config_['comparisons'][x] for x in config_['comparisons'] if config_['comparisons'][x]['indexed_col'] == col_and_value][0]\n",
    "                n_comparisons = len(config_['comparisons'].keys())\n",
    "\n",
    "                sim_for_pair_of_cols = similarity_hub(n_comparisons, comparison_info, cols_and_values[col_and_value], candidate['_source'][col_and_value])\n",
    "\n",
    "                sim_candidate.append(sim_for_pair_of_cols)\n",
    "\n",
    "        score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "        score = (sum(sim_candidate))/score_max\n",
    "    \n",
    "        scores[candidate_id] = score\n",
    "    \n",
    "#     # taking those records with the same 'id'\n",
    "#     scores.pop(str(id_value), None)\n",
    "    \n",
    "    # finding the best score and id\n",
    "    if len(scores) > 0:\n",
    "        best_score_id = max(scores, key=scores.get)\n",
    "        best_score_value = scores[best_score_id]\n",
    "    else: \n",
    "        best_score_id = 'null'\n",
    "        best_score_value = '0.0'\n",
    "        scores = '{}'\n",
    "    return best_score_id, best_score_value, scores\n",
    "    \n",
    "    \n",
    "def similarity_hub(n_comparisons, comparison_info, col_and_value, candidate):\n",
    "    \"\"\"\n",
    "    Currently the CIDACS-RL uses overlap for categorical data, jaro_winkler for names and hamming for dates.\n",
    "    \"\"\"\n",
    "    import jellyfish\n",
    "    \n",
    "    # getting relevant information for this pair of values\n",
    "    config_ = config_bc.value\n",
    "#     score_max = sum([float(config_['comparisons'][x]['weight']) for x in config_['comparisons']])\n",
    "    similarity = 0.0\n",
    "    weight = float(comparison_info['weight'])\n",
    "    penalty = float(comparison_info['penalty'])\n",
    "    \n",
    "    # first, test if some value are missing\n",
    "    if (candidate == config_['null_value']) or (col_and_value == config_['null_value'])\\\n",
    "        or (candidate == \"\") or (col_and_value == \"\") or (candidate == None) or (col_and_value == None):\n",
    "        similarity = similarity - penalty\n",
    "    else: \n",
    "        sim_type = comparison_info['similarity']\n",
    "        if (sim_type == 'overlap') and (col_and_value == candidate):\n",
    "            similarity += (1.0) * weight\n",
    "            return similarity\n",
    "        elif (sim_type == 'overlap') and (col_and_value != candidate):\n",
    "            similarity += 0.0\n",
    "            return similarity\n",
    "        elif sim_type == 'jaro_winkler':\n",
    "            similarity += jellyfish.jaro_winkler(col_and_value, candidate) * weight\n",
    "        elif sim_type == 'hamming':\n",
    "            max_size = max(len(col_and_value), len(candidate))\n",
    "            similarity += 1.0 - float(jellyfish.hamming_distance(col_and_value, candidate)/max_size) * weight\n",
    "        else: \n",
    "            print('Please inform valid similarities for cidacs-rl')\n",
    "        \n",
    "        similarity = similarity\n",
    "    return similarity    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cidacs_rl_exact_phase(tolink_dataset):\n",
    "    \"\"\"\n",
    "    This function take a dataframe to link with an indexed dataframe on elasticsearch.\n",
    "    It consists in three main steps: \n",
    "        1) The first step consists in create an array column from a set of columns used on integration\n",
    "        \n",
    "        withColumn('vars', F.array(tolink_cols)) input: \n",
    "        +-----------+--------------------+------+\n",
    "        |id_cidacs_b|                nome|  sexo|\n",
    "        +-----------+--------------------+------+\n",
    "        |          0|    ROBESPIERRE PITA|     1|\n",
    "        +-----------+--------------------+------+\n",
    "        \n",
    "        withColumn('vars', F.array(tolink_cols)) output: \n",
    "        +-----------+--------------------+------+--------------------------+\n",
    "        |id_cidacs_b|                nome|  sexo|                      vars|\n",
    "        +-----------+--------------------+------+--------------------------+\n",
    "        |        614|    ROBESPIERRE PITA|     1|  [0, ROBESPIERRE PITA, 1]|\n",
    "        +-----------+--------------------+------+--------------------------+\n",
    "        \n",
    "        2) The second step will take the new array col as input and build exact queries:\n",
    "        \n",
    "        udf_build_exact_queries(F.col('vars')) output:\n",
    "        \n",
    "        { \"size\": \"50\",\n",
    "            \"query\": { \"bool\": \n",
    "            { \"must\": [ \n",
    "                {\"match\": {\"nome_a\":\"ROBESPIERRE PITA\"}},\n",
    "                {\"match\": {\"sexo_a\":\"1\"}} ] } } }\n",
    "        \n",
    "        +-----------+-----------------+------+--------------------------+----------------+\n",
    "        |id_cidacs_b|             nome|  sexo|                      vars|     exact_query|\n",
    "        +-----------+-----------------+------+--------------------------+----------------+\n",
    "        |        614|    ROBESPIERR...|     1|  [0, ROBESPIERRE PITA, 1]| { \"size\": \"5...|\n",
    "        +-----------+-----------------+------+--------------------------+----------------+\n",
    "        \n",
    "        3) Finally, a udf should generate 3 new columns with the best candidate id, the similarity with \n",
    "           this best candidate, and the set of candidates scores. \n",
    "        \n",
    "        +--------------------+------------------------+---------------------------+\n",
    "        |best_candidate_exact|sim_best_candidate_exact|similarity_exact_candidates|\n",
    "        +--------------------+------------------------+---------------------------+\n",
    "        |                 614|                       1|        {614: 1, 34: 0.8...|\n",
    "        +--------------------+------------------------+---------------------------+\n",
    "        \n",
    "    At last, this function should return the tolink_dataset with all these columns\n",
    "    \"\"\" \n",
    "    # ------------------------------------ #\n",
    "    # getting relevant values from config\n",
    "    # ------------------------------------ #\n",
    "    \n",
    "    # collecting config json from broadcasted variable\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    tolink_id_column = config_['datasets_info']['tolink_dataset']['id_column_name']\n",
    "    tolink_cols = config_['datasets_info']['tolink_dataset']['columns']\n",
    "    \n",
    "    tolink_columns = config_['datasets_info']['tolink_dataset']['columns']\n",
    "    \n",
    "    temp_dir = config['temp_dir']\n",
    "    \n",
    "    # ------------------------------------ #\n",
    "    # preparing exact search\n",
    "    # ------------------------------------ #\n",
    "    # selecting columns\n",
    "    tolink_dataset = tolink_dataset.select(tolink_columns)\n",
    "    # building array of variable values\n",
    "    tolink_dataset = tolink_dataset.withColumn('vars', F.array(tolink_cols))\n",
    "    # building exact queries\n",
    "    tolink_dataset = tolink_dataset.withColumn('exact_queries', udf_build_exact_queries(F.col('vars')))\n",
    "    # finding the best candidate for each tolink record\n",
    "    tolink_dataset = tolink_dataset.withColumn('result_exact_search', F.explode(F.array(udf_find_elasticsearch_exact_best_candidate(F.col('vars'), F.col('exact_queries')))))\n",
    "    \n",
    "    # writing temporary data from this point helps to reset the DAG and improve performance\n",
    "    tolink_dataset.write.parquet(temp_dir+'result_exact_search.parquet', mode='overwrite')\n",
    "    tolink_dataset = spark.read.parquet(temp_dir+'result_exact_search.parquet')\n",
    "    \n",
    "    # exploding array columns from the last function into 4 atomic cols\n",
    "    tolink_dataset = tolink_dataset.withColumn('best_candidate_exact', tolink_dataset.result_exact_search['best_candidate_exact'])\n",
    "    tolink_dataset = tolink_dataset.withColumn('sim_best_candidate_exact', tolink_dataset.result_exact_search['sim_best_candidate_exact'])\n",
    "    tolink_dataset = tolink_dataset.withColumn('similarity_exact_candidates', tolink_dataset.result_exact_search['similarity_exact_candidates'])\n",
    "    \n",
    "    tolink_dataset = tolink_dataset.withColumn('sim_best_candidate_exact', F.col('sim_best_candidate_exact').cast('float'))\n",
    "    \n",
    "    # dropping array columns\n",
    "    cols_to_drop = ['result_exact_search']\n",
    "    tolink_dataset = tolink_dataset.drop(*cols_to_drop)\n",
    "    \n",
    "    return tolink_dataset\n",
    "\n",
    "\n",
    "\n",
    "def cidacs_rl_non_exact_phase(tolink_dataset):\n",
    "    \"\"\"\n",
    "    This function take a dataframe from exact match phase and submit it to a non exact search.\n",
    "    cidacs_rl_non_exact_phase(tolink_dataset) input: \n",
    "    \n",
    "    +--------------------------+--------------------+------------------------+---------------------------+\n",
    "    |                      vars|best_candidate_exact|sim_best_candidate_exact|similarity_exact_candidates|\n",
    "    +--------------------------+--------------------+------------------------+---------------------------+\n",
    "    |       [2, SAMILA SENA, 2]|                null|                    null|                       null|\n",
    "    +--------------------------+--------------------+------------------------+---------------------------+\n",
    "        \n",
    "    cidacs_rl_non_exact_phase(tolink_dataset) output: \n",
    "        \n",
    "        +------------------------+----------------------------+-------------------------------+\n",
    "        |best_candidate_non_exact|sim_best_candidate_non_exact|similarity_exact_non_candidates|\n",
    "        +------------------------+----------------------------+-------------------------------+\n",
    "        |                       7|                        0.94|            {7: 0.94, 3: 0.9...|\n",
    "        +------------------------+----------------------------+-------------------------------+\n",
    "    \n",
    "    At last, this function should return the tolink_dataset with all these columns\n",
    "    \"\"\"\n",
    "    # ------------------------------------ #\n",
    "    # getting relevant values from config\n",
    "    # ------------------------------------ #\n",
    "    \n",
    "    # collecting config json from broadcasted variable\n",
    "    config_ = config_bc.value\n",
    "    \n",
    "    tolink_id_column = config_['datasets_info']['tolink_dataset']['id_column_name']\n",
    "    tolink_cols = config_['datasets_info']['tolink_dataset']['columns']\n",
    "    \n",
    "    tolink_columns = config_['datasets_info']['tolink_dataset']['columns']\n",
    "    \n",
    "    temp_dir = config_['temp_dir']\n",
    "    \n",
    "    is_debug = config_['debug']\n",
    "\n",
    "    # ------------------------------------ #\n",
    "    # preparing non exact search\n",
    "    # ------------------------------------ #\n",
    "    \n",
    "    # building linked_from column. Non-null values on sim_best_candidate_exact must be filled \n",
    "    # as 'exact_match', otherwise as 'non_exact_match'.    \n",
    "    filter_isnull = F.col('sim_best_candidate_exact').isNull()\n",
    "    tolink_dataset = tolink_dataset.withColumn('linked_from', F.when(filter_isnull, 'non_exact_match').otherwise('exact_match'))\n",
    "    \n",
    "    # preparing filters for debug and non-debug executions\n",
    "    filter_exact = F.col('linked_from') == 'exact_match'\n",
    "    filter_non_exact = F.col('linked_from') == 'non_exact_match'\n",
    "    \n",
    "    if is_debug == 'false': \n",
    "        # declaring a filtered version of input dataset\n",
    "        tolink_dataset_ = tolink_dataset.filter(filter_non_exact)\n",
    "        # declaring the remainder dataframe\n",
    "        tolink_dataset = tolink_dataset.filter(filter_exact)\n",
    "        \n",
    "        # creating, for remainder dataframe, the cols created in this function to ensure union\n",
    "        tolink_dataset = tolink_dataset.withColumn('best_candidate_non_exact', F.lit(None))\n",
    "        tolink_dataset = tolink_dataset.withColumn('sim_best_candidate_non_exact', F.lit(None))\n",
    "        tolink_dataset = tolink_dataset.withColumn('similarity_non_exact_candidates', F.lit(None))\n",
    "        tolink_dataset = tolink_dataset.withColumn('non_exact_queries', F.lit(None))\n",
    "    else: \n",
    "        # inside dataframe receives the input integrally\n",
    "        tolink_dataset_ = tolink_dataset\n",
    "    \n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('non_exact_queries', udf_build_non_exact_queries(F.col('vars')))\n",
    "\n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('result_non_exact_search', F.explode(F.array(udf_find_elasticsearch_non_exact_best_candidate(F.col('vars'), F.col('non_exact_queries')))))\n",
    "    # writing temporary data from this point helps to reset the DAG and improve performance\n",
    "    tolink_dataset_.write.parquet(temp_dir+'result_non_exact_search.parquet', mode='overwrite')\n",
    "    tolink_dataset_ = spark.read.parquet(temp_dir+'result_non_exact_search.parquet')\n",
    "\n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('best_candidate_non_exact', tolink_dataset_.result_non_exact_search['best_candidate_non_exact'])\n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('sim_best_candidate_non_exact', tolink_dataset_.result_non_exact_search['sim_best_candidate_non_exact'])\n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('similarity_non_exact_candidates', tolink_dataset_.result_non_exact_search['similarity_non_exact_candidates'])\n",
    "    \n",
    "    tolink_dataset_ = tolink_dataset_.withColumn('sim_best_candidate_non_exact', F.col('sim_best_candidate_non_exact').cast('float'))\n",
    "    \n",
    "    cols_to_drop = ['result_non_exact_search']\n",
    "    tolink_dataset_ = tolink_dataset_.drop(*cols_to_drop)\n",
    "    \n",
    "    if is_debug == 'false':\n",
    "        tolink_dataset_ = tolink_dataset_.union(tolink_dataset)\n",
    "    \n",
    "    return tolink_dataset_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading prepocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the auxiliary variables\n",
    "data_ext = config['datasets_info']['indexed_dataset']['extension']\n",
    "data_path = config['datasets_info']['indexed_dataset']['path']\n",
    "\n",
    "# test the extension of the dataset to properly read it\n",
    "if data_ext == 'csv':\n",
    "    indexed_dataset = spark.read.csv(data_path, header=True)\n",
    "elif data_ext == 'parquet':\n",
    "    indexed_dataset = spark.read.parquet(data_path)\n",
    "else:\n",
    "    print(\"Please make sure the extension for this dataset is set as 'csv' or 'parquet'\")\n",
    "    \n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.regexp_replace(F.col('dt_nasc_a'), \"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>sexo_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>YASMIM VITORIA MATIAS FONSECA</td>\n",
       "      <td>TACIANY DOS SANTOS</td>\n",
       "      <td>20071122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>20061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>20071107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_a                              nome_a  \\\n",
       "0           1       YASMIM VITORIA MATIAS FONSECA   \n",
       "1           2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "2           3       FABRICIO RODRIGUES DOS SANTOS   \n",
       "\n",
       "                     nome_mae_a dt_nasc_a  sexo_a  \n",
       "0            TACIANY DOS SANTOS  20071122       2  \n",
       "1  FRANCILEIDE DOS SANTOS ALVES  20061102       1  \n",
       "2      MARCELA MACHADO DA SILVA  20071107       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the auxiliary variables\n",
    "data_ext = config['datasets_info']['tolink_dataset']['extension']\n",
    "data_path = config['datasets_info']['tolink_dataset']['path']\n",
    "\n",
    "# test the extension of the dataset to properly read it\n",
    "if data_ext == 'csv':\n",
    "    tolink_dataset = spark.read.csv(data_path, header=True)\n",
    "elif data_ext == 'parquet':\n",
    "    tolink_dataset = spark.read.parquet(data_path)\n",
    "else:\n",
    "    print(\"Please make sure the extension for this dataset is set as 'csv' or 'parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing tolink dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tolink_dataset.columns:\n",
    "    tolink_dataset = tolink_dataset.withColumn(col, F.col(col).cast('string'))\n",
    "\n",
    "tolink_dataset = tolink_dataset.na.fill(config['null_value'])\n",
    "\n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "tolink_dataset = tolink_dataset.withColumn('dt_nasc_b', F.regexp_replace(F.col('dt_nasc_b'), \"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614</td>\n",
       "      <td>GEDSON TIAGO PEDRO DA SILVA</td>\n",
       "      <td>ANA KAROLINE MOREIRA DA SILVA</td>\n",
       "      <td>20071209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2113</td>\n",
       "      <td>ANA BEATRIZ DOS SANTOS NASCIMENTO</td>\n",
       "      <td>ELCIENA AIRES PEREIRA</td>\n",
       "      <td>20080403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2185</td>\n",
       "      <td>JOAO PEDRO DA SILVA RIBEIRO</td>\n",
       "      <td>FRANCILENE MENDONCA LOPES</td>\n",
       "      <td>20080129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                             nome_b  \\\n",
       "0         614        GEDSON TIAGO PEDRO DA SILVA   \n",
       "1        2113  ANA BEATRIZ DOS SANTOS NASCIMENTO   \n",
       "2        2185        JOAO PEDRO DA SILVA RIBEIRO   \n",
       "\n",
       "                      nome_mae_b dt_nasc_b sexo_b  \n",
       "0  ANA KAROLINE MOREIRA DA SILVA  20071209      1  \n",
       "1          ELCIENA AIRES PEREIRA  20080403      2  \n",
       "2      FRANCILENE MENDONCA LOPES  20080129      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure all the cols in data are StringType()\n",
    "\n",
    "# for col in indexed_dataset.columns:\n",
    "#     indexed_dataset = indexed_dataset.withColumn(col, F.col(col).cast('string'))\n",
    "\n",
    "# indexed_dataset = indexed_dataset.na.fill(config['null_value'])\n",
    "    \n",
    "# # All the hyphens symbols must be taken from date type variables converted to string\n",
    "# indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.regexp_replace(F.col('dt_nasc_a'), \"-\", \"\"))\n",
    "\n",
    "# # indexing, at last\n",
    "# index_df_response = config['index_data']\n",
    "# index_name = config['es_index_name']\n",
    "# if index_df_response == 'yes':\n",
    "#     index_dataframe(indexed_dataset, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'match': {'nome_a': {'query': 'ROBESPIERRE PITA', 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = { \"size\": \"50\", \n",
    "#            \"query\": {\n",
    "#                \"bool\": { \n",
    "#                    \"should\": [ \n",
    "#                        {\"match\": {\"nome_a\": { \"query\" :\"GEDSON TIAGO PEDRO DA SILVA\", \"fuzziness\":\"AUTO\", \"operator\":\"or\", \"boost\":\"3.0\" }}},\n",
    "#                        {\"match\": {\"nome_mae_a\":\" { \"query\" :ANA KAROLINE MOREIRA DA SILVA\", \"fuzziness\":\"AUTO\", \"operator\":\"or\", \"boost\":\"2.0\" }}},\n",
    "#                        {\"term\": {\"sexo_a\":\"1\"}} ] } } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = config['es_index_name']\n",
    "# es = Elasticsearch('http://localhost:9200')\n",
    "# content = { \"size\": 50,\n",
    "#             \"query\": { \n",
    "#                  \"bool\": { \n",
    "#                      \"should\": [ \n",
    "#                          {\"match\": {\"nome_a\" : {\"query\":\"GEDSON TIAGO PEDRO\", \"fuzziness\":\"AUTO\", \"operator\":\"or\", \"boost\":\"3.0\"}}},\n",
    "#                          {\"match\": {\"birthdate\":\"20071209\"}},\n",
    "#                          {\"term\": {\"sexo_a\":\"1\"}} ] } } }\n",
    "# candidates = es.search(index=index_name, body=content)['hits']['hits']\n",
    "# candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = config['es_index_name']\n",
    "# es = Elasticsearch('http://localhost:9200')\n",
    "# content = {\n",
    "#     'size': 1,\n",
    "#     'query': {\n",
    "#         'bool': {\n",
    "#             'must': [\n",
    "#                 {'match': {'dt_nasc_a': '20070816'}}\n",
    "#             ]\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# candidates = es.search(index=index_name, body=content)['hits']['hits']\n",
    "# candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "      <th>best_candidate_exact</th>\n",
       "      <th>sim_best_candidate_exact</th>\n",
       "      <th>similarity_exact_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614</td>\n",
       "      <td>GEDSON TIAGO PEDRO DA SILVA</td>\n",
       "      <td>ANA KAROLINE MOREIRA DA SILVA</td>\n",
       "      <td>20071209</td>\n",
       "      <td>1</td>\n",
       "      <td>[614, GEDSON TIAGO PEDRO DA SILVA, ANA KAROLIN...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{349022=0.8239223722436063, 521940=0.781458805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2113</td>\n",
       "      <td>ANA BEATRIZ DOS SANTOS NASCIMENTO</td>\n",
       "      <td>ELCIENA AIRES PEREIRA</td>\n",
       "      <td>20080403</td>\n",
       "      <td>2</td>\n",
       "      <td>[2113, ANA BEATRIZ DOS SANTOS NASCIMENTO, ELCI...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>2113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{50708=0.787398656759559, 705715=0.81794235458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2185</td>\n",
       "      <td>JOAO PEDRO DA SILVA RIBEIRO</td>\n",
       "      <td>FRANCILENE MENDONCA LOPES</td>\n",
       "      <td>20080129</td>\n",
       "      <td>1</td>\n",
       "      <td>[2185, JOAO PEDRO DA SILVA RIBEIRO, FRANCILENE...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>2185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{973930=0.8205208009129578, 749099=0.795151828...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                             nome_b  \\\n",
       "0         614        GEDSON TIAGO PEDRO DA SILVA   \n",
       "1        2113  ANA BEATRIZ DOS SANTOS NASCIMENTO   \n",
       "2        2185        JOAO PEDRO DA SILVA RIBEIRO   \n",
       "\n",
       "                      nome_mae_b dt_nasc_b sexo_b  \\\n",
       "0  ANA KAROLINE MOREIRA DA SILVA  20071209      1   \n",
       "1          ELCIENA AIRES PEREIRA  20080403      2   \n",
       "2      FRANCILENE MENDONCA LOPES  20080129      1   \n",
       "\n",
       "                                                vars  \\\n",
       "0  [614, GEDSON TIAGO PEDRO DA SILVA, ANA KAROLIN...   \n",
       "1  [2113, ANA BEATRIZ DOS SANTOS NASCIMENTO, ELCI...   \n",
       "2  [2185, JOAO PEDRO DA SILVA RIBEIRO, FRANCILENE...   \n",
       "\n",
       "                                       exact_queries best_candidate_exact  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                  614   \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 2113   \n",
       "2  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 2185   \n",
       "\n",
       "   sim_best_candidate_exact                        similarity_exact_candidates  \n",
       "0                       1.0  {349022=0.8239223722436063, 521940=0.781458805...  \n",
       "1                       1.0  {50708=0.787398656759559, 705715=0.81794235458...  \n",
       "2                       1.0  {973930=0.8205208009129578, 749099=0.795151828...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = cidacs_rl_exact_phase(tolink_dataset)\n",
    "print(tolink_dataset.count())\n",
    "tolink_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "      <th>best_candidate_exact</th>\n",
       "      <th>sim_best_candidate_exact</th>\n",
       "      <th>similarity_exact_candidates</th>\n",
       "      <th>linked_from</th>\n",
       "      <th>non_exact_queries</th>\n",
       "      <th>best_candidate_non_exact</th>\n",
       "      <th>sim_best_candidate_non_exact</th>\n",
       "      <th>similarity_non_exact_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355705</td>\n",
       "      <td>KASSIO LUCAS DA SILVA COSTA</td>\n",
       "      <td>99</td>\n",
       "      <td>20070717</td>\n",
       "      <td>1</td>\n",
       "      <td>[355705, KASSIO LUCAS DA SILVA COSTA, 99, 2007...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>non_exact_match</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"should\":...</td>\n",
       "      <td>355705</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>{46009=0.6146428571428572, 626689=0.5967857142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>886</td>\n",
       "      <td>MARIA CLARA</td>\n",
       "      <td>ANGELICA CRISTINA SOUZA</td>\n",
       "      <td>20070628</td>\n",
       "      <td>1</td>\n",
       "      <td>[886, MARIA CLARA, ANGELICA CRISTINA SOUZA, 20...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>non_exact_match</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"should\":...</td>\n",
       "      <td>942580</td>\n",
       "      <td>0.872237</td>\n",
       "      <td>{398558=0.5492066977574224, 468949=0.590958394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3230</td>\n",
       "      <td>MARCELO DANIEL</td>\n",
       "      <td>CARLA ANDREA DA C</td>\n",
       "      <td>20080712</td>\n",
       "      <td>2</td>\n",
       "      <td>[3230, MARCELO DANIEL, CARLA ANDREA DA C, 2008...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>non_exact_match</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"should\":...</td>\n",
       "      <td>806504</td>\n",
       "      <td>0.857310</td>\n",
       "      <td>{390350=0.6102841136454582, 429062=0.663887777...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                       nome_b               nome_mae_b dt_nasc_b  \\\n",
       "0      355705  KASSIO LUCAS DA SILVA COSTA                       99  20070717   \n",
       "1         886                  MARIA CLARA  ANGELICA CRISTINA SOUZA  20070628   \n",
       "2        3230               MARCELO DANIEL        CARLA ANDREA DA C  20080712   \n",
       "\n",
       "  sexo_b                                               vars  \\\n",
       "0      1  [355705, KASSIO LUCAS DA SILVA COSTA, 99, 2007...   \n",
       "1      1  [886, MARIA CLARA, ANGELICA CRISTINA SOUZA, 20...   \n",
       "2      2  [3230, MARCELO DANIEL, CARLA ANDREA DA C, 2008...   \n",
       "\n",
       "                                       exact_queries best_candidate_exact  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 null   \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 null   \n",
       "2  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 null   \n",
       "\n",
       "   sim_best_candidate_exact similarity_exact_candidates      linked_from  \\\n",
       "0                       NaN                        null  non_exact_match   \n",
       "1                       NaN                        null  non_exact_match   \n",
       "2                       NaN                        null  non_exact_match   \n",
       "\n",
       "                                   non_exact_queries best_candidate_non_exact  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"should\":...                   355705   \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"should\":...                   942580   \n",
       "2  { \"size\": \"50\", \"query\": { \"bool\": { \"should\":...                   806504   \n",
       "\n",
       "   sim_best_candidate_non_exact  \\\n",
       "0                      0.641429   \n",
       "1                      0.872237   \n",
       "2                      0.857310   \n",
       "\n",
       "                     similarity_non_exact_candidates  \n",
       "0  {46009=0.6146428571428572, 626689=0.5967857142...  \n",
       "1  {398558=0.5492066977574224, 468949=0.590958394...  \n",
       "2  {390350=0.6102841136454582, 429062=0.663887777...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = cidacs_rl_non_exact_phase(tolink_dataset)\n",
    "print(tolink_dataset.count())\n",
    "tolink_dataset.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>vars</th>\n",
       "      <th>exact_queries</th>\n",
       "      <th>best_candidate_exact</th>\n",
       "      <th>sim_best_candidate_exact</th>\n",
       "      <th>similarity_exact_candidates</th>\n",
       "      <th>linked_from</th>\n",
       "      <th>non_exact_queries</th>\n",
       "      <th>best_candidate_non_exact</th>\n",
       "      <th>sim_best_candidate_non_exact</th>\n",
       "      <th>similarity_non_exact_candidates</th>\n",
       "      <th>final_cidacs_rl_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355705</td>\n",
       "      <td>KASSIO LUCAS DA SILVA COSTA</td>\n",
       "      <td>99</td>\n",
       "      <td>20070717</td>\n",
       "      <td>1</td>\n",
       "      <td>[355705, KASSIO LUCAS DA SILVA COSTA, 99, 2007...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>non_exact_match</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"should\":...</td>\n",
       "      <td>355705</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>{46009=0.6146428571428572, 626689=0.5967857142...</td>\n",
       "      <td>0.641429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>886</td>\n",
       "      <td>MARIA CLARA</td>\n",
       "      <td>ANGELICA CRISTINA SOUZA</td>\n",
       "      <td>20070628</td>\n",
       "      <td>1</td>\n",
       "      <td>[886, MARIA CLARA, ANGELICA CRISTINA SOUZA, 20...</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...</td>\n",
       "      <td>null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>non_exact_match</td>\n",
       "      <td>{ \"size\": \"50\", \"query\": { \"bool\": { \"should\":...</td>\n",
       "      <td>942580</td>\n",
       "      <td>0.872237</td>\n",
       "      <td>{398558=0.5492066977574224, 468949=0.590958394...</td>\n",
       "      <td>0.872237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                       nome_b               nome_mae_b dt_nasc_b  \\\n",
       "0      355705  KASSIO LUCAS DA SILVA COSTA                       99  20070717   \n",
       "1         886                  MARIA CLARA  ANGELICA CRISTINA SOUZA  20070628   \n",
       "\n",
       "  sexo_b                                               vars  \\\n",
       "0      1  [355705, KASSIO LUCAS DA SILVA COSTA, 99, 2007...   \n",
       "1      1  [886, MARIA CLARA, ANGELICA CRISTINA SOUZA, 20...   \n",
       "\n",
       "                                       exact_queries best_candidate_exact  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 null   \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"must\": [...                 null   \n",
       "\n",
       "   sim_best_candidate_exact similarity_exact_candidates      linked_from  \\\n",
       "0                       NaN                        null  non_exact_match   \n",
       "1                       NaN                        null  non_exact_match   \n",
       "\n",
       "                                   non_exact_queries best_candidate_non_exact  \\\n",
       "0  { \"size\": \"50\", \"query\": { \"bool\": { \"should\":...                   355705   \n",
       "1  { \"size\": \"50\", \"query\": { \"bool\": { \"should\":...                   942580   \n",
       "\n",
       "   sim_best_candidate_non_exact  \\\n",
       "0                      0.641429   \n",
       "1                      0.872237   \n",
       "\n",
       "                     similarity_non_exact_candidates  final_cidacs_rl_score  \n",
       "0  {46009=0.6146428571428572, 626689=0.5967857142...               0.641429  \n",
       "1  {398558=0.5492066977574224, 468949=0.590958394...               0.872237  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset = tolink_dataset.withColumn('final_cidacs_rl_score', F.when(F.col('linked_from') == 'exact_match', F.col('sim_best_candidate_exact')).otherwise(F.col('sim_best_candidate_non_exact')))\n",
    "tolink_dataset.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.33012199401855\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolink_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    linked_from|count|\n",
      "+---------------+-----+\n",
      "|    exact_match|  501|\n",
      "|non_exact_match|  499|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolink_dataset.select('linked_from').groupBy('linked_from').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|summary|final_cidacs_rl_score|\n",
      "+-------+---------------------+\n",
      "|  count|                 1000|\n",
      "|   mean|   0.9259814857840538|\n",
      "| stddev|   0.0807181069854674|\n",
      "|    min|            0.5306251|\n",
      "|    max|                  1.0|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolink_dataset.withColumn('final_cidacs_rl_score', F.when(F.col('linked_from') == 'exact_match', F.col('sim_best_candidate_exact')).otherwise(F.col('sim_best_candidate_non_exact'))).select('final_cidacs_rl_score').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    linked_from|count|\n",
      "+---------------+-----+\n",
      "|    exact_match|  501|\n",
      "|non_exact_match|  499|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tolink_dataset.withColumn('final_cidacs_rl_score', F.when(F.col('linked_from') == 'exact_match', F.col('sim_best_candidate_exact')).otherwise(F.col('sim_best_candidate_non_exact'))).select('linked_from').groupBy('linked_from').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
