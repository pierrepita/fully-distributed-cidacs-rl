{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_data': 'yes',\n",
       " 'es_index_name': 'fd-cidacs-rl',\n",
       " 'es_connect_string': 'http://localhost:9200',\n",
       " 'query_size': 50,\n",
       " 'cutoff_exact_match': '0.95',\n",
       " 'null_value': '99',\n",
       " 'temp_dir': '../0_global_data/fd-cidacs-rl/temp_dataframe/',\n",
       " 'debug': 'false',\n",
       " 'datasets_info': {'indexed_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-dataset-A.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_a', 'nome_a', 'nome_mae_a', 'dt_nasc_a', 'sexo_a'],\n",
       "   'id_column_name': 'id_cidacs_a',\n",
       "   'storage_level': 'MEMORY_ONLY',\n",
       "   'default_paralelism': '96'},\n",
       "  'tolink_dataset': {'path': '../0_global_data/fd-cidacs-rl/sinthetic-datasets-b/sinthetic-datasets-b-1000.parquet',\n",
       "   'extension': 'parquet',\n",
       "   'columns': ['id_cidacs_b', 'nome_b', 'nome_mae_b', 'dt_nasc_b', 'sexo_b'],\n",
       "   'id_column_name': 'id_cidacs_b',\n",
       "   'storage_level': 'MEMORY_ONLY',\n",
       "   'default_paralelism': '96'},\n",
       "  'result_dataset': {'path': '../0_global_data/result/'}},\n",
       " 'comparisons': {'name': {'indexed_col': 'nome_a',\n",
       "   'tolink_col': 'nome_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '3.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 5.0,\n",
       "   'penalty': 0.02},\n",
       "  'mothers_name': {'indexed_col': 'nome_mae_a',\n",
       "   'tolink_col': 'nome_mae_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'true',\n",
       "   'boost': '2.0',\n",
       "   'query_type': 'match',\n",
       "   'similarity': 'jaro_winkler',\n",
       "   'weight': 5.0,\n",
       "   'penalty': 0.02},\n",
       "  'birthdate': {'indexed_col': 'dt_nasc_a',\n",
       "   'tolink_col': 'dt_nasc_b',\n",
       "   'must_match': 'false',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'hamming',\n",
       "   'weight': 1.0,\n",
       "   'penalty': 0.02},\n",
       "  'sex': {'indexed_col': 'sexo_a',\n",
       "   'tolink_col': 'sexo_b',\n",
       "   'must_match': 'true',\n",
       "   'should_match': 'true',\n",
       "   'is_fuzzy': 'false',\n",
       "   'boost': '',\n",
       "   'query_type': 'term',\n",
       "   'similarity': 'overlap',\n",
       "   'weight': 3.0,\n",
       "   'penalty': 0.02}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('config.txt')\n",
    "config = json.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading prepocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>sexo_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>YASMIM VITORIA MATIAS FONSECA</td>\n",
       "      <td>TACIANY DOS SANTOS</td>\n",
       "      <td>20071122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>20061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>20071107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>VINICIUS DA SILVA SOUZA</td>\n",
       "      <td>ELIZANGELA LIMA DA SILVA</td>\n",
       "      <td>20071008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LUAN FERREIRA DO NASCIMENTO</td>\n",
       "      <td>KEZIA NUNES GALDINO MONTEIRO</td>\n",
       "      <td>20080128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_a                              nome_a  \\\n",
       "0           1       YASMIM VITORIA MATIAS FONSECA   \n",
       "1           2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "2           3       FABRICIO RODRIGUES DOS SANTOS   \n",
       "3           4             VINICIUS DA SILVA SOUZA   \n",
       "4           5         LUAN FERREIRA DO NASCIMENTO   \n",
       "\n",
       "                     nome_mae_a dt_nasc_a sexo_a  \n",
       "0            TACIANY DOS SANTOS  20071122      2  \n",
       "1  FRANCILEIDE DOS SANTOS ALVES  20061102      1  \n",
       "2      MARCELA MACHADO DA SILVA  20071107      1  \n",
       "3      ELIZANGELA LIMA DA SILVA  20071008      1  \n",
       "4  KEZIA NUNES GALDINO MONTEIRO  20080128      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the auxiliary variables\n",
    "data_ext = config['datasets_info']['indexed_dataset']['extension']\n",
    "data_path = config['datasets_info']['indexed_dataset']['path']\n",
    "\n",
    "# test the extension of the dataset to properly read it\n",
    "if data_ext == 'csv':\n",
    "    indexed_dataset = spark.read.csv(data_path, header=True)\n",
    "elif data_ext == 'parquet':\n",
    "    indexed_dataset = spark.read.parquet(data_path)\n",
    "else:\n",
    "    print(\"Please make sure the extension for this dataset is set as 'csv' or 'parquet'\")\n",
    "\n",
    "# indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.to_date(F.col('dt_nasc_a'), 'dd/MM/yyyy'))\n",
    "    \n",
    "for col in indexed_dataset.columns:\n",
    "    indexed_dataset = indexed_dataset.withColumn(col, F.col(col).cast('string'))\n",
    "\n",
    "indexed_dataset = indexed_dataset.na.fill(config['null_value'])\n",
    "\n",
    "# All the hyphens symbols must be taken from date type variables converted to string\n",
    "# indexed_dataset = indexed_dataset.withColumn('dt_nasc_a', F.regexp_replace(F.col('dt_nasc_a'), \"-\", \"\"))\n",
    "indexed_dataset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed_dataset = spark.read.csv('/home/pierre/Dropbox/repos/0_global_data/fd-cidacs-rl/sinthetic-dataset-A.csv', header=True)\n",
    "# indexed_dataset.write.parquet('/home/pierre/Dropbox/repos/0_global_data/fd-cidacs-rl/sinthetic-dataset-A_.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sinthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supress_last_name(col):\n",
    "    col = str(col)\n",
    "    return ' '.join(col.split(' ')[:-1])\n",
    "udf_supress_last_name = F.udf(supress_last_name, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../0_global_data/fd-cidacs-rl/sinthetic-datasets-b/sinthetic-datasets-b-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sizes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_df': 56, 'gray_df': 19, 'false_df': 9974, 'accum_size': 10049, 'final_size': 100}\n",
      "{'true_df': 257, 'gray_df': 104, 'false_df': 9955, 'accum_size': 10316, 'final_size': 500}\n",
      "{'true_df': 542, 'gray_df': 210, 'false_df': 10284, 'accum_size': 11036, 'final_size': 1000}\n",
      "{'true_df': 2498, 'gray_df': 1005, 'false_df': 11509, 'accum_size': 15012, 'final_size': 5000}\n",
      "{'true_df': 4905, 'gray_df': 1979, 'false_df': 13061, 'accum_size': 19945, 'final_size': 10000}\n",
      "{'true_df': 25150, 'gray_df': 10065, 'false_df': 25297, 'accum_size': 60512, 'final_size': 50000}\n",
      "{'true_df': 50329, 'gray_df': 20271, 'false_df': 39895, 'accum_size': 110495, 'final_size': 100000}\n",
      "{'true_df': 250964, 'gray_df': 99792, 'false_df': 160060, 'accum_size': 510816, 'final_size': 500000}\n",
      "{'true_df': 499976, 'gray_df': 200552, 'false_df': 309944, 'accum_size': 1010472, 'final_size': 1000000}\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    accum_size = 0\n",
    "    map_sizes[str(size)] = {}\n",
    "    # setting the proportions of exact true matches, gray area and false matches\n",
    "    # ~50% of true matches\n",
    "    # ~20% of gray area (record with last name supression and wrong information on sex)\n",
    "    # ~30% of false matches\n",
    "    n_true_m = (size/100)*50\n",
    "    n_gray_m = (size/100)*20\n",
    "    n_false_m = (size/100)*30\n",
    "    \n",
    "    # using literal numbers to estimate the right proportion of sample\n",
    "    p_true_m = n_true_m/1000000\n",
    "    p_gray_m = n_gray_m/1000000\n",
    "    p_false_m = (n_false_m/1000000)+ 0.01\n",
    "    \n",
    "    # getting sample of exact true\n",
    "    true_df = indexed_dataset.sample(p_true_m)\n",
    "    count = true_df.count()\n",
    "    accum_size += count\n",
    "    map_sizes[str(size)]['true_df'] = count\n",
    "    \n",
    "    # getting sample of gray area\n",
    "    gray_df = indexed_dataset.sample(p_gray_m)\n",
    "    count = gray_df.count()\n",
    "    accum_size += count\n",
    "    map_sizes[str(size)]['gray_df'] = count\n",
    "    \n",
    "    # getting sample of false matches\n",
    "    false_df = indexed_dataset.sample(p_false_m)\n",
    "    count = false_df.count()\n",
    "    accum_size += count\n",
    "    map_sizes[str(size)]['false_df'] = count\n",
    "    \n",
    "    # recording the total size of resulting datasets\n",
    "    map_sizes[str(size)]['accum_size'] = accum_size\n",
    "    \n",
    "    # suppressing last name and changing sex info for gray area records\n",
    "    gray_df = gray_df.withColumn('nome_a', udf_supress_last_name(F.col('nome_a')))\n",
    "    gray_df = gray_df.withColumn('nome_mae_a', udf_supress_last_name(F.col('nome_mae_a')))\n",
    "    gray_df = gray_df.withColumn('sexo_a', F.when(F.col('sexo_a') == 1, 2).otherwise(1))\n",
    "    \n",
    "    \n",
    "    # messing with name for false matches\n",
    "    false_df = false_df.withColumn('nome_a', F.col('nome_mae_a'))\n",
    "    \n",
    "    # union\n",
    "    df = true_df.union(gray_df).union(false_df).limit(size)\n",
    "    \n",
    "#     df = df.withColumn('dt_nasc_a', F.to_date(F.col('dt_nasc_a'), 'dd/MM/yyyy'))\n",
    "#     df = df.withColumn('dt_nasc_a', F.col('dt_nasc_a').cast('string'))\n",
    "    \n",
    "    count = df.count()\n",
    "    map_sizes[str(size)]['final_size'] = count\n",
    "    \n",
    "    # changing names\n",
    "    names_dict = {'id_cidacs_a': 'id_cidacs_b', \n",
    "                  'nome_a': 'nome_b', \n",
    "                  'nome_mae_a': 'nome_mae_b', \n",
    "                  'dt_nasc_a': 'dt_nasc_b', \n",
    "                  'sexo_a': 'sexo_b'}\n",
    "    for col in names_dict.keys():\n",
    "        df = df.withColumnRenamed(col, names_dict[col])\n",
    "    \n",
    "    # writing data\n",
    "    df.write.parquet(prefix+str(size)+'.parquet', mode='overwrite')\n",
    "    print(map_sizes[str(size)])\n",
    "\n",
    "# map_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>453</td>\n",
       "      <td>DAVI MATHEUS DOS SANTOS FARIAS</td>\n",
       "      <td>JUCIENE RAMOS DOS SANTOS</td>\n",
       "      <td>20070721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>CAIO FURLAN CRESPO</td>\n",
       "      <td>ELEN CRISTINA DE OLIVEIRA CARVALHO</td>\n",
       "      <td>20061015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206</td>\n",
       "      <td>CARLOS GABRIEL CARVALHO DE SOUZA</td>\n",
       "      <td>LEUDILENE DA COSTA SILVA</td>\n",
       "      <td>20080319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1413</td>\n",
       "      <td>JOSIANE DOS SANTOS FERREIRA</td>\n",
       "      <td>ALDENIRA RODRIGUES SANTOS</td>\n",
       "      <td>20080126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1551</td>\n",
       "      <td>YASMIM CAROLINA LOPES GONCALVES</td>\n",
       "      <td>JOANA FATIMA AYRES</td>\n",
       "      <td>20080117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                            nome_b  \\\n",
       "0         453    DAVI MATHEUS DOS SANTOS FARIAS   \n",
       "1        1073                CAIO FURLAN CRESPO   \n",
       "2        1206  CARLOS GABRIEL CARVALHO DE SOUZA   \n",
       "3        1413       JOSIANE DOS SANTOS FERREIRA   \n",
       "4        1551   YASMIM CAROLINA LOPES GONCALVES   \n",
       "\n",
       "                           nome_mae_b dt_nasc_b sexo_b  \n",
       "0            JUCIENE RAMOS DOS SANTOS  20070721      1  \n",
       "1  ELEN CRISTINA DE OLIVEIRA CARVALHO  20061015      1  \n",
       "2            LEUDILENE DA COSTA SILVA  20080319      1  \n",
       "3           ALDENIRA RODRIGUES SANTOS  20080126      2  \n",
       "4                  JOANA FATIMA AYRES  20080117      2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing one dataset\n",
    "spark.read.parquet('../0_global_data/fd-cidacs-rl/sinthetic-datasets-b/sinthetic-datasets-b-10000.parquet/').limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
