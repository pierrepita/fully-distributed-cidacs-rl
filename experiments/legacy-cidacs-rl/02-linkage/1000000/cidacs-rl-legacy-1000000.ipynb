{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '1000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
    "range_years = list(range(int(2008),2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listPath(path, recur=False, pattern=None, partitioned=False):\n",
    "    result = []\n",
    "    if path.startswith('hdfs'): \n",
    "        result = hdfs.ls(path, recursive=recur)\n",
    "    else:\n",
    "        if recur:\n",
    "            bases = []\n",
    "            for root, dirnames, filenames in os.walk(path):\n",
    "                bases += [root + '/' + x for x in filenames]\n",
    "            result = bases\n",
    "        else:\n",
    "            result = os.listdir(path)\n",
    "    if partitioned:\n",
    "        result = ['/'.join(x.split('/')[:-1]) for x in result if partitioned in x]\n",
    "        result = list(set(result))\n",
    "    if pattern:\n",
    "        result = [x for x in result if x.endswith(pattern)]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base to read,  write and es index\n",
    "# Paths need to end with '/'\n",
    "sourceFileName = \".csv\"\n",
    "sourceBase = \"../../../../0_global_data/fd-cidacs-rl/sinthetic-datasets-b-legacy/sinthetic-datasets-b-\"+size+\".csv/\" # Example: hdfs:///npd/trusted/data/base_sim/05_linkage_extraction/\n",
    "targetBase = \"../../../../0_global_results/fd-cidacs-rl/legacy/\" # Example: hdfs:///npd/refined/data/linkage_base_sim_x_base_sinasc/\n",
    "index_name = \"fd-cidacs-rl-legacy\" # Example: sinasc_maes_2001a2015_dtnascmae_nulo\n",
    "# hdfs.mkdir(targetBase)\n",
    "os.system('mkdir ' + targetBase)\n",
    "bases = listPath(sourceBase, pattern=sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-82d7d52e-f477-41b3-97cc-3f9a2e0f9c2d-c000.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic search and start thread pool\n",
    "ncores = 3\n",
    "pool = ThreadPool(ncores)\n",
    "es = Elasticsearch('http://localhost:9200', maxsize=ncores, timeout=30, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for reference\n",
    "indexedBaseHeader = \"A\" # Example: sinasc\n",
    "sourceBaseHeader = \"B\" # Example: sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>VINICIUS DA SILVA SOUZA</td>\n",
       "      <td>ELIZANGELA LIMA DA SILVA</td>\n",
       "      <td>20071008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>LUAN FERREIRA DO NASCIMENTO</td>\n",
       "      <td>KEZIA NUNES GALDINO MONTEIRO</td>\n",
       "      <td>20080128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>JOAO PEDRO BATISTA DOS SANTOS</td>\n",
       "      <td>SOILA COSTA DA SILVA</td>\n",
       "      <td>20070903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>GABRIEL COUTO GOMES</td>\n",
       "      <td>ROSILDA LEAL BARBOSA</td>\n",
       "      <td>20061008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>LUIZA VITORIA BATISTA DOS SANTOS</td>\n",
       "      <td>EDILZA MAGALHAES DE SOUZA MARTINS</td>\n",
       "      <td>20061027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>MABYLA TAHANNA DE OLIVEIRA LOURENCO</td>\n",
       "      <td>KLAUCIARA DA SILVA PENNA</td>\n",
       "      <td>20070821</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>JASMYNNE ELOYSE NUNES SANTANA</td>\n",
       "      <td>MARLI BARBOSA</td>\n",
       "      <td>20070724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>MARCOS GABRIEL SILVA FERREIRA</td>\n",
       "      <td>MARISSA KATHLEN S ROCHA</td>\n",
       "      <td>20070706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>VITOR CORDEIRO DOS SANTOS</td>\n",
       "      <td>SUELLI RIBEIRO SALUSTINO</td>\n",
       "      <td>20070902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>CARLOS EDUARDO MARTINS VIEIRA</td>\n",
       "      <td>ELIANA DE ARAUJO LORENCO</td>\n",
       "      <td>20070810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                               nome_b  \\\n",
       "0           4              VINICIUS DA SILVA SOUZA   \n",
       "1           5          LUAN FERREIRA DO NASCIMENTO   \n",
       "2           7        JOAO PEDRO BATISTA DOS SANTOS   \n",
       "3           9                  GABRIEL COUTO GOMES   \n",
       "4          10     LUIZA VITORIA BATISTA DOS SANTOS   \n",
       "5          12  MABYLA TAHANNA DE OLIVEIRA LOURENCO   \n",
       "6          13        JASMYNNE ELOYSE NUNES SANTANA   \n",
       "7          14        MARCOS GABRIEL SILVA FERREIRA   \n",
       "8          16            VITOR CORDEIRO DOS SANTOS   \n",
       "9          22        CARLOS EDUARDO MARTINS VIEIRA   \n",
       "\n",
       "                          nome_mae_b dt_nasc_b sexo_b  \n",
       "0           ELIZANGELA LIMA DA SILVA  20071008      1  \n",
       "1       KEZIA NUNES GALDINO MONTEIRO  20080128      1  \n",
       "2               SOILA COSTA DA SILVA  20070903      1  \n",
       "3               ROSILDA LEAL BARBOSA  20061008      1  \n",
       "4  EDILZA MAGALHAES DE SOUZA MARTINS  20061027      2  \n",
       "5           KLAUCIARA DA SILVA PENNA  20070821      2  \n",
       "6                      MARLI BARBOSA  20070724      2  \n",
       "7            MARISSA KATHLEN S ROCHA  20070706      1  \n",
       "8           SUELLI RIBEIRO SALUSTINO  20070902      1  \n",
       "9           ELIANA DE ARAUJO LORENCO  20070810      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(sourceBase, header=True).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bases = []\n",
    "for source in bases:\n",
    "    # Open csv base\n",
    "    with open(sourceBase + source, 'r') as base:\n",
    "        dic_base = list()\n",
    "        header = True\n",
    "        #If csv contains header as first line, skip it\n",
    "        for l in base:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            # Split csv line\n",
    "            l = l.replace('\\n', '').split(',')\n",
    "            # Get each char\n",
    "            seq = l[0].strip()\n",
    "            nome_b = l[1].strip()\n",
    "            nome_mae_b = l[2].strip()\n",
    "            dt_nasc_b = l[3].strip()\n",
    "            sexo_b = l[4].strip()\n",
    "            \n",
    "\n",
    "            # If all fields are blanks, then don't add the register, add it otherwise.\n",
    "            if not (dt_nasc_b == '' and nome_b == '' and nome_mae_b == '' and sexo_b == ''):\n",
    "                content = {\n",
    "                'seq':seq,\n",
    "                'nome_b':unicode(nome_b),\n",
    "                'nome_mae_b':unicode(nome_mae_b),\n",
    "                'dt_nasc_b':unicode(dt_nasc_b),\n",
    "                'sexo_b':unicode(sexo_b)\n",
    "                }\n",
    "                dic_base.append(content)\n",
    "    dic_bases.append(dic_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-82d7d52e-f477-41b3-97cc-3f9a2e0f9c2d-c000.csv 1000000\n"
     ]
    }
   ],
   "source": [
    "# Number of registers for each base\n",
    "for i in range(len(dic_bases)):\n",
    "    print(bases[i].split('/')[-1], len(dic_bases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exact search on elastic search function\n",
    "def searchExactPerson(nome_b, nome_mae_b, sexo_b, startId=0):\n",
    "    \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'nome_a': nome_b}},\n",
    "                    {'match': {'nome_mae_a': nome_mae_b}},\n",
    "                    {'match': {'sexo_a': sexo_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']\n",
    "\n",
    "# Fuzzy search on elastic search function\n",
    "def searchFuzzyPerson(nome_b, nome_mae_b, dt_nasc_b, sexo_b, startId=0):\n",
    "  \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'nome_a': {'query': nome_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'nome_mae_a': {'query': nome_mae_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'sexo_a': {'query': sexo_b}}},\n",
    "                    {'term': {'dt_nasc_a': dt_nasc_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestCandidate(candidates, person):\n",
    "    if candidates:\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            score = compare(candidate['_source'], person)\n",
    "            scores.append((score, candidate))\n",
    "#         scores.sort(reverse=True) do not fit on python 3.x, it raises TypeError: '<' not supported between instances of 'dict' and 'dict'\n",
    "        scores.sort(key=lambda x: x[0], reverse=True) \n",
    "        bestCandidate = scores[0][1]\n",
    "        bestScore = scores[0][0]\n",
    "        bestCandidate['_source']['score'] = bestScore\n",
    "        return bestCandidate\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(candidate, source):\n",
    "    # Weights\n",
    "    nome_w = 5.0\n",
    "    nome_mae_w = 5.0\n",
    "    dt_nasc_w = 1.0\n",
    "    sexo_w = 3.0\n",
    "\n",
    "    nome_penalty = 0.02\n",
    "    nome_mae_penalty = 0.02\n",
    "    dt_nasc_penalty = 0.02\n",
    "    sexo_penalty = 0.02\n",
    "\n",
    "    # Max score\n",
    "    score_max = nome_w + nome_mae_w + dt_nasc_w + sexo_w\n",
    "\n",
    "    # Initialize scores and penalties\n",
    "    score_nome, score_nome_mae, score_dt_nasc, score_sexo, penalty = 0, 0, 0, 0, 0\n",
    "\n",
    "    # Compare addresses name with jaro distance\n",
    "    if candidate['nome_a'] == '' or source['nome_b'] == '':\n",
    "        score_max -= nome_w\n",
    "        penalty += nome_penalty\n",
    "    else:\n",
    "        score_nome = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_w\n",
    "\n",
    "\n",
    "    if candidate['nome_mae_a'] == '' or source['nome_mae_b'] == '':\n",
    "        score_max -= nome_mae_w\n",
    "        penalty += nome_mae_penalty\n",
    "    else:\n",
    "        score_nome_mae = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_mae_w\n",
    "\n",
    "    if candidate['dt_nasc_a'] == '' or source['dt_nasc_b'] == '':\n",
    "        score_max -= dt_nasc_w\n",
    "        penalty += dt_nasc_penalty\n",
    "    else:\n",
    "        score_dt_nasc = (1.0 - float(jellyfish.hamming_distance(candidate['dt_nasc_a'], source['dt_nasc_b'])) / max(len(candidate['dt_nasc_a']), len(source['dt_nasc_b']))) * dt_nasc_w\n",
    "\n",
    "\n",
    "   # Compare sex\n",
    "    if candidate['sexo_a'] == '' or source['sexo_b'] == '' :\n",
    "        score_max -= sexo_w\n",
    "        penalty += sexo_penalty\n",
    "    elif candidate['sexo_a'] == source['sexo_b'] :\n",
    "        score_sexo += sexo_w\n",
    "            \n",
    "    score = ((score_nome + score_nome_mae + score_dt_nasc + score_sexo) / score_max) - penalty\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cidacsrl(source):\n",
    "#     print(source)\n",
    "    result = ''\n",
    "    #Perform exact search\n",
    "    candidates = searchExactPerson(nome_b=source['nome_b'],\n",
    "                                   nome_mae_b=source['nome_mae_b'],\n",
    "                                   sexo_b=source['sexo_b'])\n",
    "    \n",
    "    bestCandidate = findBestCandidate(candidates, source)\n",
    "    \n",
    "    if candidates and bestCandidate['_source']['score'] >= .95:\n",
    "            \n",
    "        score = str(bestCandidate['_source']['score'])\n",
    "\n",
    "        searchType = 'searchExactPerson'\n",
    "\n",
    "        fields = [bestCandidate['_id'], source['seq'],\n",
    "                  bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                  bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                  bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                  bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'],\n",
    "                  searchType, score]\n",
    "        result = ','.join(fields) + '\\n'\n",
    "\n",
    "    # If no candidate is selected, perform fuzzy search\n",
    "    else:\n",
    "        candidates = searchFuzzyPerson(nome_b=source['nome_b'],\n",
    "                                       nome_mae_b=source['nome_mae_b'],\n",
    "                                       sexo_b=source['sexo_b'],\n",
    "                                       dt_nasc_b=source['dt_nasc_b'])\n",
    "        \n",
    "        bestCandidate = findBestCandidate(candidates, source)\n",
    "        if bestCandidate:\n",
    "            score = str(bestCandidate['_source']['score'])\n",
    "            \n",
    "            searchType = 'searchFuzzyPerson'\n",
    "            \n",
    "            fields = [bestCandidate['_id'], source['seq'], \n",
    "                      bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                      bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                      bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                      bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'], \n",
    "                      searchType, score]\n",
    "            result = ','.join(fields) + '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datamart header\n",
    "headerFields = ['seq', 'nome', 'nome_mae', 'dt_nasc', 'sexo']\n",
    "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
    "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
    "l = []\n",
    "for i in range(len(larger)):\n",
    "    l.append(larger[i])\n",
    "    l.append(smaller[i])\n",
    "\n",
    "l.append('searchType')\n",
    "l.append('score')\n",
    "header = ','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 0.221700% \\ the estimated remaining time is roughly: 4:03:48.217251 \\ total elapsed time: 0:00:32.51752984116103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b1a249fb6458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcidacsrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic_bases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(dic_bases)):\n",
    "    marker = time.time()\n",
    "    num_tasks = len(dic_bases[i])\n",
    "    result = []\n",
    "    c, elapsed_time = 0, 0\n",
    "    for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases[i])):\n",
    "        result.append(x)\n",
    "        c += 1\n",
    "        elapsed_time = time.time() - marker\n",
    "        done = float(j)/num_tasks\n",
    "        estimated = str(datetime.timedelta(seconds=(num_tasks -c)*(elapsed_time/c)))\n",
    "        sys.stderr.write('\\rdone: {:%} \\ the estimated remaining time is roughly: {} \\ total elapsed time: {}'.format(done, estimated, str(datetime.timedelta(seconds=time.time() - marker))))\n",
    "    f = open(targetBase + bases[i].split('/')[-1], 'w')\n",
    "    f.write(header + '\\n')\n",
    "    for line in result:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
