{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '100000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listPath(path, recur=False, pattern=None, partitioned=False):\n",
    "    result = []\n",
    "    if path.startswith('hdfs'): \n",
    "        result = hdfs.ls(path, recursive=recur)\n",
    "    else:\n",
    "        if recur:\n",
    "            bases = []\n",
    "            for root, dirnames, filenames in os.walk(path):\n",
    "                bases += [root + '/' + x for x in filenames]\n",
    "            result = bases\n",
    "        else:\n",
    "            result = os.listdir(path)\n",
    "    if partitioned:\n",
    "        result = ['/'.join(x.split('/')[:-1]) for x in result if partitioned in x]\n",
    "        result = list(set(result))\n",
    "    if pattern:\n",
    "        result = [x for x in result if x.endswith(pattern)]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base to read,  write and es index\n",
    "# Paths need to end with '/'\n",
    "sourceFileName = \".csv\"\n",
    "sourceBase = \"../../../../../0_global_data/fd-cidacs-rl/sinthetic-datasets-b-legacy/sinthetic-datasets-b-\"+size+\".csv/\" # Example: hdfs:///npd/trusted/data/base_sim/05_linkage_extraction/\n",
    "targetBase = \"../../../../../0_global_results/fd-cidacs-rl/legacy/\" # Example: hdfs:///npd/refined/data/linkage_base_sim_x_base_sinasc/\n",
    "index_name = \"fd-cidacs-rl-legacy\" # Example: sinasc_maes_2001a2015_dtnascmae_nulo\n",
    "# hdfs.mkdir(targetBase)\n",
    "os.system('mkdir ' + targetBase)\n",
    "bases = listPath(sourceBase, pattern=sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-2aedfabd-5d63-4d15-9e95-1a19211a4bb9-c000.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic search and start thread pool\n",
    "ncores = 3\n",
    "pool = ThreadPool(ncores)\n",
    "es = Elasticsearch('http://localhost:9200', maxsize=ncores, timeout=30, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for reference\n",
    "indexedBaseHeader = \"A\" # Example: sinasc\n",
    "sourceBaseHeader = \"B\" # Example: sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>BARBARA CAROLINE LEITE DE OLIVEIRA</td>\n",
       "      <td>FRANCISCA ANDREZA S DO NASCIMENTO</td>\n",
       "      <td>20080103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>JUAN RODRIGUES DA SILVA</td>\n",
       "      <td>ROSANA SERAFIM FELINTO</td>\n",
       "      <td>20071118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>KALIBE MATHEUS MATOS NERY</td>\n",
       "      <td>LUCIMAR SILVA DE MELO</td>\n",
       "      <td>20060802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>ANNA LUISA ROSA DE MOURA</td>\n",
       "      <td>LUANA ANA VILHAMES MARTINS</td>\n",
       "      <td>20070803</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>PEDRO JOSE SOUZA CALDEIRA</td>\n",
       "      <td>MARLUCIA DE JESUS F SILVA</td>\n",
       "      <td>20080303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85</td>\n",
       "      <td>LAURA LIMA DE ANDRADE</td>\n",
       "      <td>KESIA NUNES DE FONSECA</td>\n",
       "      <td>20070102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91</td>\n",
       "      <td>DAVI SANTOS FREIRE DA SILVA</td>\n",
       "      <td>MARIA DA GUIA MATIAS</td>\n",
       "      <td>20071015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>LAURA FRANCISCA DE SA SANTOS</td>\n",
       "      <td>JUCIARA BORGES PEREIRA</td>\n",
       "      <td>20070628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111</td>\n",
       "      <td>ITALO MOISES DOS SANTOS</td>\n",
       "      <td>VIVIANE APARECIDA BORGES</td>\n",
       "      <td>20071108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>121</td>\n",
       "      <td>ANIELLE SOUZA DA CONCEICAO</td>\n",
       "      <td>CLEIA DE SOUZA RODRIGUES</td>\n",
       "      <td>20080227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                              nome_b  \\\n",
       "0          25  BARBARA CAROLINE LEITE DE OLIVEIRA   \n",
       "1          31             JUAN RODRIGUES DA SILVA   \n",
       "2          43           KALIBE MATHEUS MATOS NERY   \n",
       "3          61            ANNA LUISA ROSA DE MOURA   \n",
       "4          72           PEDRO JOSE SOUZA CALDEIRA   \n",
       "5          85               LAURA LIMA DE ANDRADE   \n",
       "6          91         DAVI SANTOS FREIRE DA SILVA   \n",
       "7          96        LAURA FRANCISCA DE SA SANTOS   \n",
       "8         111             ITALO MOISES DOS SANTOS   \n",
       "9         121          ANIELLE SOUZA DA CONCEICAO   \n",
       "\n",
       "                          nome_mae_b dt_nasc_b sexo_b  \n",
       "0  FRANCISCA ANDREZA S DO NASCIMENTO  20080103      2  \n",
       "1             ROSANA SERAFIM FELINTO  20071118      1  \n",
       "2              LUCIMAR SILVA DE MELO  20060802      1  \n",
       "3         LUANA ANA VILHAMES MARTINS  20070803      2  \n",
       "4          MARLUCIA DE JESUS F SILVA  20080303      1  \n",
       "5             KESIA NUNES DE FONSECA  20070102      2  \n",
       "6               MARIA DA GUIA MATIAS  20071015      1  \n",
       "7             JUCIARA BORGES PEREIRA  20070628      2  \n",
       "8           VIVIANE APARECIDA BORGES  20071108      1  \n",
       "9           CLEIA DE SOUZA RODRIGUES  20080227      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(sourceBase, header=True).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bases = []\n",
    "for source in bases:\n",
    "    # Open csv base\n",
    "    with open(sourceBase + source, 'r') as base:\n",
    "        dic_base = list()\n",
    "        header = True\n",
    "        #If csv contains header as first line, skip it\n",
    "        for l in base:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            # Split csv line\n",
    "            l = l.replace('\\n', '').split(',')\n",
    "            # Get each char\n",
    "            seq = l[0].strip()\n",
    "            nome_b = l[1].strip()\n",
    "            nome_mae_b = l[2].strip()\n",
    "            dt_nasc_b = l[3].strip()\n",
    "            sexo_b = l[4].strip()\n",
    "            \n",
    "\n",
    "            # If all fields are blanks, then don't add the register, add it otherwise.\n",
    "            if not (dt_nasc_b == '' and nome_b == '' and nome_mae_b == '' and sexo_b == ''):\n",
    "                content = {\n",
    "                'seq':seq,\n",
    "                'nome_b':unicode(nome_b),\n",
    "                'nome_mae_b':unicode(nome_mae_b),\n",
    "                'dt_nasc_b':unicode(dt_nasc_b),\n",
    "                'sexo_b':unicode(sexo_b)\n",
    "                }\n",
    "                dic_base.append(content)\n",
    "    dic_bases.append(dic_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-2aedfabd-5d63-4d15-9e95-1a19211a4bb9-c000.csv 100000\n"
     ]
    }
   ],
   "source": [
    "# Number of registers for each base\n",
    "for i in range(len(dic_bases)):\n",
    "    print(bases[i].split('/')[-1], len(dic_bases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exact search on elastic search function\n",
    "def searchExactPerson(nome_b, nome_mae_b, sexo_b, startId=0):\n",
    "    \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'nome_a': nome_b}},\n",
    "                    {'match': {'nome_mae_a': nome_mae_b}},\n",
    "                    {'match': {'sexo_a': sexo_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']\n",
    "\n",
    "# Fuzzy search on elastic search function\n",
    "def searchFuzzyPerson(nome_b, nome_mae_b, dt_nasc_b, sexo_b, startId=0):\n",
    "  \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'nome_a': {'query': nome_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'nome_mae_a': {'query': nome_mae_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'sexo_a': {'query': sexo_b}}},\n",
    "                    {'term': {'dt_nasc_a': dt_nasc_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestCandidate(candidates, person):\n",
    "    if candidates:\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            score = compare(candidate['_source'], person)\n",
    "            scores.append((score, candidate))\n",
    "#         scores.sort(reverse=True) do not fit on python 3.x, it raises TypeError: '<' not supported between instances of 'dict' and 'dict'\n",
    "        scores.sort(key=lambda x: x[0], reverse=True) \n",
    "        bestCandidate = scores[0][1]\n",
    "        bestScore = scores[0][0]\n",
    "        bestCandidate['_source']['score'] = bestScore\n",
    "        return bestCandidate\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(candidate, source):\n",
    "    # Weights\n",
    "    nome_w = 5.0\n",
    "    nome_mae_w = 5.0\n",
    "    dt_nasc_w = 1.0\n",
    "    sexo_w = 3.0\n",
    "\n",
    "    nome_penalty = 0.02\n",
    "    nome_mae_penalty = 0.02\n",
    "    dt_nasc_penalty = 0.02\n",
    "    sexo_penalty = 0.02\n",
    "\n",
    "    # Max score\n",
    "    score_max = nome_w + nome_mae_w + dt_nasc_w + sexo_w\n",
    "\n",
    "    # Initialize scores and penalties\n",
    "    score_nome, score_nome_mae, score_dt_nasc, score_sexo, penalty = 0, 0, 0, 0, 0\n",
    "\n",
    "    # Compare addresses name with jaro distance\n",
    "    if candidate['nome_a'] == '' or source['nome_b'] == '':\n",
    "        score_max -= nome_w\n",
    "        penalty += nome_penalty\n",
    "    else:\n",
    "        score_nome = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_w\n",
    "\n",
    "\n",
    "    if candidate['nome_mae_a'] == '' or source['nome_mae_b'] == '':\n",
    "        score_max -= nome_mae_w\n",
    "        penalty += nome_mae_penalty\n",
    "    else:\n",
    "        score_nome_mae = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_mae_w\n",
    "\n",
    "    if candidate['dt_nasc_a'] == '' or source['dt_nasc_b'] == '':\n",
    "        score_max -= dt_nasc_w\n",
    "        penalty += dt_nasc_penalty\n",
    "    else:\n",
    "        score_dt_nasc = (1.0 - float(jellyfish.hamming_distance(candidate['dt_nasc_a'], source['dt_nasc_b'])) / max(len(candidate['dt_nasc_a']), len(source['dt_nasc_b']))) * dt_nasc_w\n",
    "\n",
    "\n",
    "   # Compare sex\n",
    "    if candidate['sexo_a'] == '' or source['sexo_b'] == '' :\n",
    "        score_max -= sexo_w\n",
    "        penalty += sexo_penalty\n",
    "    elif candidate['sexo_a'] == source['sexo_b'] :\n",
    "        score_sexo += sexo_w\n",
    "            \n",
    "    score = ((score_nome + score_nome_mae + score_dt_nasc + score_sexo) / score_max) - penalty\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cidacsrl(source):\n",
    "#     print(source)\n",
    "    result = ''\n",
    "    #Perform exact search\n",
    "    candidates = searchExactPerson(nome_b=source['nome_b'],\n",
    "                                   nome_mae_b=source['nome_mae_b'],\n",
    "                                   sexo_b=source['sexo_b'])\n",
    "    \n",
    "    bestCandidate = findBestCandidate(candidates, source)\n",
    "    \n",
    "    if candidates and bestCandidate['_source']['score'] >= .95:\n",
    "            \n",
    "        score = str(bestCandidate['_source']['score'])\n",
    "\n",
    "        searchType = 'searchExactPerson'\n",
    "\n",
    "        fields = [bestCandidate['_id'], source['seq'],\n",
    "                  bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                  bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                  bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                  bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'],\n",
    "                  searchType, score]\n",
    "        result = ','.join(fields) + '\\n'\n",
    "\n",
    "    # If no candidate is selected, perform fuzzy search\n",
    "    else:\n",
    "        candidates = searchFuzzyPerson(nome_b=source['nome_b'],\n",
    "                                       nome_mae_b=source['nome_mae_b'],\n",
    "                                       sexo_b=source['sexo_b'],\n",
    "                                       dt_nasc_b=source['dt_nasc_b'])\n",
    "        \n",
    "        bestCandidate = findBestCandidate(candidates, source)\n",
    "        if bestCandidate:\n",
    "            score = str(bestCandidate['_source']['score'])\n",
    "            \n",
    "            searchType = 'searchFuzzyPerson'\n",
    "            \n",
    "            fields = [bestCandidate['_id'], source['seq'], \n",
    "                      bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                      bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                      bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                      bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'], \n",
    "                      searchType, score]\n",
    "            result = ','.join(fields) + '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datamart header\n",
    "headerFields = ['seq', 'nome', 'nome_mae', 'dt_nasc', 'sexo']\n",
    "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
    "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
    "l = []\n",
    "for i in range(len(larger)):\n",
    "    l.append(larger[i])\n",
    "    l.append(smaller[i])\n",
    "\n",
    "l.append('searchType')\n",
    "l.append('score')\n",
    "header = ','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.996000% \\ the estimated remaining time is roughly: 0:00:00.119022 \\ total elapsed time: 1:06:07.271007"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.999000% \\ the estimated remaining time is roughly: 0:00:00 \\ total elapsed time: 1:06:07.610059.596317"
     ]
    }
   ],
   "source": [
    "for i in range(len(dic_bases)):\n",
    "    marker = time.time()\n",
    "    num_tasks = len(dic_bases[i])\n",
    "    result = []\n",
    "    c, elapsed_time = 0, 0\n",
    "    for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases[i])):\n",
    "        result.append(x)\n",
    "        c += 1\n",
    "        elapsed_time = time.time() - marker\n",
    "        done = float(j)/num_tasks\n",
    "        estimated = str(datetime.timedelta(seconds=(num_tasks -c)*(elapsed_time/c)))\n",
    "        sys.stderr.write('\\rdone: {:%} \\ the estimated remaining time is roughly: {} \\ total elapsed time: {}'.format(done, estimated, str(datetime.timedelta(seconds=time.time() - marker))))\n",
    "    f = open(targetBase + bases[i].split('/')[-1], 'w')\n",
    "    f.write(header + '\\n')\n",
    "    for line in result:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de execução: 3973.629725217819 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo total de execução: {} secs\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_A</th>\n",
       "      <th>seq_B</th>\n",
       "      <th>nome_A</th>\n",
       "      <th>nome_B</th>\n",
       "      <th>nome_mae_A</th>\n",
       "      <th>nome_mae_B</th>\n",
       "      <th>dt_nasc_A</th>\n",
       "      <th>dt_nasc_B</th>\n",
       "      <th>sexo_A</th>\n",
       "      <th>sexo_B</th>\n",
       "      <th>searchType</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>JUAN RODRIGUES DA SILVA</td>\n",
       "      <td>JUAN RODRIGUES DA SILVA</td>\n",
       "      <td>ROSANA SERAFIM FELINTO</td>\n",
       "      <td>ROSANA SERAFIM FELINTO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20071118</td>\n",
       "      <td>20071118</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>KALIBE MATHEUS MATOS NERY</td>\n",
       "      <td>KALIBE MATHEUS MATOS NERY</td>\n",
       "      <td>LUCIMAR SILVA DE MELO</td>\n",
       "      <td>LUCIMAR SILVA DE MELO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20060802</td>\n",
       "      <td>20060802</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>BARBARA CAROLINE LEITE DE OLIVEIRA</td>\n",
       "      <td>BARBARA CAROLINE LEITE DE OLIVEIRA</td>\n",
       "      <td>FRANCISCA ANDREZA S DO NASCIMENTO</td>\n",
       "      <td>FRANCISCA ANDREZA S DO NASCIMENTO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080103</td>\n",
       "      <td>20080103</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>ANNA LUISA ROSA DE MOURA</td>\n",
       "      <td>ANNA LUISA ROSA DE MOURA</td>\n",
       "      <td>LUANA ANA VILHAMES MARTINS</td>\n",
       "      <td>LUANA ANA VILHAMES MARTINS</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20070803</td>\n",
       "      <td>20070803</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>LAURA LIMA DE ANDRADE</td>\n",
       "      <td>LAURA LIMA DE ANDRADE</td>\n",
       "      <td>KESIA NUNES DE FONSECA</td>\n",
       "      <td>KESIA NUNES DE FONSECA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20070102</td>\n",
       "      <td>20070102</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq_A seq_B                              nome_A  \\\n",
       "0    31    31             JUAN RODRIGUES DA SILVA   \n",
       "1    43    43           KALIBE MATHEUS MATOS NERY   \n",
       "2    25    25  BARBARA CAROLINE LEITE DE OLIVEIRA   \n",
       "3    61    61            ANNA LUISA ROSA DE MOURA   \n",
       "4    85    85               LAURA LIMA DE ANDRADE   \n",
       "\n",
       "                               nome_B                         nome_mae_A  \\\n",
       "0             JUAN RODRIGUES DA SILVA             ROSANA SERAFIM FELINTO   \n",
       "1           KALIBE MATHEUS MATOS NERY              LUCIMAR SILVA DE MELO   \n",
       "2  BARBARA CAROLINE LEITE DE OLIVEIRA  FRANCISCA ANDREZA S DO NASCIMENTO   \n",
       "3            ANNA LUISA ROSA DE MOURA         LUANA ANA VILHAMES MARTINS   \n",
       "4               LAURA LIMA DE ANDRADE             KESIA NUNES DE FONSECA   \n",
       "\n",
       "                          nome_mae_B dt_nasc_A dt_nasc_B    sexo_A    sexo_B  \\\n",
       "0             ROSANA SERAFIM FELINTO         1         1  20071118  20071118   \n",
       "1              LUCIMAR SILVA DE MELO         1         1  20060802  20060802   \n",
       "2  FRANCISCA ANDREZA S DO NASCIMENTO         2         2  20080103  20080103   \n",
       "3         LUANA ANA VILHAMES MARTINS         2         2  20070803  20070803   \n",
       "4             KESIA NUNES DE FONSECA         2         2  20070102  20070102   \n",
       "\n",
       "          searchType score  \n",
       "0  searchExactPerson   1.0  \n",
       "1  searchExactPerson   1.0  \n",
       "2  searchExactPerson   1.0  \n",
       "3  searchExactPerson   1.0  \n",
       "4  searchExactPerson   1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.read.csv('../../../../../0_global_results/fd-cidacs-rl/legacy/part-00000-2aedfabd-5d63-4d15-9e95-1a19211a4bb9-c000.csv', header=True)\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|       searchType|count|\n",
      "+-----------------+-----+\n",
      "|searchFuzzyPerson|48459|\n",
      "|searchExactPerson|51541|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('searchType').groupBy('searchType').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
