{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listPath(path, recur=False, pattern=None, partitioned=False):\n",
    "    result = []\n",
    "    if path.startswith('hdfs'): \n",
    "        result = hdfs.ls(path, recursive=recur)\n",
    "    else:\n",
    "        if recur:\n",
    "            bases = []\n",
    "            for root, dirnames, filenames in os.walk(path):\n",
    "                bases += [root + '/' + x for x in filenames]\n",
    "            result = bases\n",
    "        else:\n",
    "            result = os.listdir(path)\n",
    "    if partitioned:\n",
    "        result = ['/'.join(x.split('/')[:-1]) for x in result if partitioned in x]\n",
    "        result = list(set(result))\n",
    "    if pattern:\n",
    "        result = [x for x in result if x.endswith(pattern)]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base to read,  write and es index\n",
    "# Paths need to end with '/'\n",
    "sourceFileName = \".csv\"\n",
    "sourceBase = \"../../../../../0_global_data/fd-cidacs-rl/sinthetic-datasets-b-legacy/sinthetic-datasets-b-\"+size+\".csv/\" # Example: hdfs:///npd/trusted/data/base_sim/05_linkage_extraction/\n",
    "targetBase = \"../../../../../0_global_results/fd-cidacs-rl/legacy/\" # Example: hdfs:///npd/refined/data/linkage_base_sim_x_base_sinasc/\n",
    "index_name = \"fd-cidacs-rl-legacy\" # Example: sinasc_maes_2001a2015_dtnascmae_nulo\n",
    "# hdfs.mkdir(targetBase)\n",
    "os.system('mkdir ' + targetBase)\n",
    "bases = listPath(sourceBase, pattern=sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-606cf15c-b1ef-4370-8b8b-2dbd69714870-c000.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic search and start thread pool\n",
    "ncores = 4\n",
    "pool = ThreadPool(ncores)\n",
    "es = Elasticsearch('http://localhost:9200', maxsize=ncores, timeout=30, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for reference\n",
    "indexedBaseHeader = \"A\" # Example: sinasc\n",
    "sourceBaseHeader = \"B\" # Example: sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>453</td>\n",
       "      <td>DAVI MATHEUS DOS SANTOS FARIAS</td>\n",
       "      <td>JUCIENE RAMOS DOS SANTOS</td>\n",
       "      <td>20070721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>CAIO FURLAN CRESPO</td>\n",
       "      <td>ELEN CRISTINA DE OLIVEIRA CARVALHO</td>\n",
       "      <td>20061015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1206</td>\n",
       "      <td>CARLOS GABRIEL CARVALHO DE SOUZA</td>\n",
       "      <td>LEUDILENE DA COSTA SILVA</td>\n",
       "      <td>20080319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1413</td>\n",
       "      <td>JOSIANE DOS SANTOS FERREIRA</td>\n",
       "      <td>ALDENIRA RODRIGUES SANTOS</td>\n",
       "      <td>20080126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1551</td>\n",
       "      <td>YASMIM CAROLINA LOPES GONCALVES</td>\n",
       "      <td>JOANA FATIMA AYRES</td>\n",
       "      <td>20080117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1640</td>\n",
       "      <td>EMILLY SEABRA DIAS</td>\n",
       "      <td>SIONE CONCEICAO</td>\n",
       "      <td>20080710</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1682</td>\n",
       "      <td>KAROLYNE YASMIN MARQUES GOMES</td>\n",
       "      <td>MARIA FELISE NASCIMENTO</td>\n",
       "      <td>20080814</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1817</td>\n",
       "      <td>MARIA CLARA MUNIZ SERRAO</td>\n",
       "      <td>SUELEN VASCONCELOS NEVES</td>\n",
       "      <td>20080726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1827</td>\n",
       "      <td>MARIA CLARA REGO LIMA</td>\n",
       "      <td>NOEMIA OLIVEIRA</td>\n",
       "      <td>20080726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1961</td>\n",
       "      <td>ANA BEATRIZ LOPES DE ARAUJO</td>\n",
       "      <td>ADRIANA OLIVEIRA SIQUEIRA</td>\n",
       "      <td>20080717</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                            nome_b  \\\n",
       "0         453    DAVI MATHEUS DOS SANTOS FARIAS   \n",
       "1        1073                CAIO FURLAN CRESPO   \n",
       "2        1206  CARLOS GABRIEL CARVALHO DE SOUZA   \n",
       "3        1413       JOSIANE DOS SANTOS FERREIRA   \n",
       "4        1551   YASMIM CAROLINA LOPES GONCALVES   \n",
       "5        1640                EMILLY SEABRA DIAS   \n",
       "6        1682     KAROLYNE YASMIN MARQUES GOMES   \n",
       "7        1817          MARIA CLARA MUNIZ SERRAO   \n",
       "8        1827             MARIA CLARA REGO LIMA   \n",
       "9        1961       ANA BEATRIZ LOPES DE ARAUJO   \n",
       "\n",
       "                           nome_mae_b dt_nasc_b sexo_b  \n",
       "0            JUCIENE RAMOS DOS SANTOS  20070721      1  \n",
       "1  ELEN CRISTINA DE OLIVEIRA CARVALHO  20061015      1  \n",
       "2            LEUDILENE DA COSTA SILVA  20080319      1  \n",
       "3           ALDENIRA RODRIGUES SANTOS  20080126      2  \n",
       "4                  JOANA FATIMA AYRES  20080117      2  \n",
       "5                     SIONE CONCEICAO  20080710      2  \n",
       "6             MARIA FELISE NASCIMENTO  20080814      2  \n",
       "7            SUELEN VASCONCELOS NEVES  20080726      2  \n",
       "8                     NOEMIA OLIVEIRA  20080726      2  \n",
       "9           ADRIANA OLIVEIRA SIQUEIRA  20080717      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(sourceBase, header=True).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bases = []\n",
    "for source in bases:\n",
    "    # Open csv base\n",
    "    with open(sourceBase + source, 'r') as base:\n",
    "        dic_base = list()\n",
    "        header = True\n",
    "        #If csv contains header as first line, skip it\n",
    "        for l in base:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            # Split csv line\n",
    "            l = l.replace('\\n', '').split(',')\n",
    "            # Get each char\n",
    "            seq = l[0].strip()\n",
    "            nome_b = l[1].strip()\n",
    "            nome_mae_b = l[2].strip()\n",
    "            dt_nasc_b = l[3].strip()\n",
    "            sexo_b = l[4].strip()\n",
    "            \n",
    "\n",
    "            # If all fields are blanks, then don't add the register, add it otherwise.\n",
    "            if not (dt_nasc_b == '' and nome_b == '' and nome_mae_b == '' and sexo_b == ''):\n",
    "                content = {\n",
    "                'seq':seq,\n",
    "                'nome_b':unicode(nome_b),\n",
    "                'nome_mae_b':unicode(nome_mae_b),\n",
    "                'dt_nasc_b':unicode(dt_nasc_b),\n",
    "                'sexo_b':unicode(sexo_b)\n",
    "                }\n",
    "                dic_base.append(content)\n",
    "    dic_bases.append(dic_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-606cf15c-b1ef-4370-8b8b-2dbd69714870-c000.csv 10000\n"
     ]
    }
   ],
   "source": [
    "# Number of registers for each base\n",
    "for i in range(len(dic_bases)):\n",
    "    print(bases[i].split('/')[-1], len(dic_bases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact search on elastic search function\n",
    "def searchExactPerson(nome_b, nome_mae_b, sexo_b, startId=0):\n",
    "    \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'nome_a': nome_b}},\n",
    "                    {'match': {'nome_mae_a': nome_mae_b}},\n",
    "                    {'match': {'sexo_a': sexo_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']\n",
    "\n",
    "# Fuzzy search on elastic search function\n",
    "def searchFuzzyPerson(nome_b, nome_mae_b, dt_nasc_b, sexo_b, startId=0):\n",
    "  \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'nome_a': {'query': nome_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'nome_mae_a': {'query': nome_mae_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'sexo_a': {'query': sexo_b}}},\n",
    "                    {'term': {'dt_nasc_a': dt_nasc_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestCandidate(candidates, person):\n",
    "    if candidates:\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            score = compare(candidate['_source'], person)\n",
    "            scores.append((score, candidate))\n",
    "#         scores.sort(reverse=True) do not fit on python 3.x, it raises TypeError: '<' not supported between instances of 'dict' and 'dict'\n",
    "        scores.sort(key=lambda x: x[0], reverse=True) \n",
    "        bestCandidate = scores[0][1]\n",
    "        bestScore = scores[0][0]\n",
    "        bestCandidate['_source']['score'] = bestScore\n",
    "        return bestCandidate\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(candidate, source):\n",
    "    # Weights\n",
    "    nome_w = 5.0\n",
    "    nome_mae_w = 5.0\n",
    "    dt_nasc_w = 1.0\n",
    "    sexo_w = 3.0\n",
    "\n",
    "    nome_penalty = 0.02\n",
    "    nome_mae_penalty = 0.02\n",
    "    dt_nasc_penalty = 0.02\n",
    "    sexo_penalty = 0.02\n",
    "\n",
    "    # Max score\n",
    "    score_max = nome_w + nome_mae_w + dt_nasc_w + sexo_w\n",
    "\n",
    "    # Initialize scores and penalties\n",
    "    score_nome, score_nome_mae, score_dt_nasc, score_sexo, penalty = 0, 0, 0, 0, 0\n",
    "\n",
    "    # Compare addresses name with jaro distance\n",
    "    if candidate['nome_a'] == '' or source['nome_b'] == '':\n",
    "        score_max -= nome_w\n",
    "        penalty += nome_penalty\n",
    "    else:\n",
    "        score_nome = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_w\n",
    "\n",
    "\n",
    "    if candidate['nome_mae_a'] == '' or source['nome_mae_b'] == '':\n",
    "        score_max -= nome_mae_w\n",
    "        penalty += nome_mae_penalty\n",
    "    else:\n",
    "        score_nome_mae = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_mae_w\n",
    "\n",
    "    if candidate['dt_nasc_a'] == '' or source['dt_nasc_b'] == '':\n",
    "        score_max -= dt_nasc_w\n",
    "        penalty += dt_nasc_penalty\n",
    "    else:\n",
    "        score_dt_nasc = (1.0 - float(jellyfish.hamming_distance(candidate['dt_nasc_a'], source['dt_nasc_b'])) / max(len(candidate['dt_nasc_a']), len(source['dt_nasc_b']))) * dt_nasc_w\n",
    "\n",
    "\n",
    "   # Compare sex\n",
    "    if candidate['sexo_a'] == '' or source['sexo_b'] == '' :\n",
    "        score_max -= sexo_w\n",
    "        penalty += sexo_penalty\n",
    "    elif candidate['sexo_a'] == source['sexo_b'] :\n",
    "        score_sexo += sexo_w\n",
    "            \n",
    "    score = ((score_nome + score_nome_mae + score_dt_nasc + score_sexo) / score_max) - penalty\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cidacsrl(source):\n",
    "#     print(source)\n",
    "    result = ''\n",
    "    #Perform exact search\n",
    "    candidates = searchExactPerson(nome_b=source['nome_b'],\n",
    "                                   nome_mae_b=source['nome_mae_b'],\n",
    "                                   sexo_b=source['sexo_b'])\n",
    "    \n",
    "    bestCandidate = findBestCandidate(candidates, source)\n",
    "    \n",
    "    if candidates and bestCandidate['_source']['score'] >= .95:\n",
    "            \n",
    "        score = str(bestCandidate['_source']['score'])\n",
    "\n",
    "        searchType = 'searchExactPerson'\n",
    "\n",
    "        fields = [bestCandidate['_id'], source['seq'],\n",
    "                  bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                  bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                  bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                  bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'],\n",
    "                  searchType, score]\n",
    "        result = ','.join(fields) + '\\n'\n",
    "\n",
    "    # If no candidate is selected, perform fuzzy search\n",
    "    else:\n",
    "        candidates = searchFuzzyPerson(nome_b=source['nome_b'],\n",
    "                                       nome_mae_b=source['nome_mae_b'],\n",
    "                                       sexo_b=source['sexo_b'],\n",
    "                                       dt_nasc_b=source['dt_nasc_b'])\n",
    "        \n",
    "        bestCandidate = findBestCandidate(candidates, source)\n",
    "        if bestCandidate:\n",
    "            score = str(bestCandidate['_source']['score'])\n",
    "            \n",
    "            searchType = 'searchFuzzyPerson'\n",
    "            \n",
    "            fields = [bestCandidate['_id'], source['seq'], \n",
    "                      bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                      bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                      bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                      bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'], \n",
    "                      searchType, score]\n",
    "            result = ','.join(fields) + '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datamart header\n",
    "headerFields = ['seq', 'nome', 'nome_mae', 'dt_nasc', 'sexo']\n",
    "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
    "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
    "l = []\n",
    "for i in range(len(larger)):\n",
    "    l.append(larger[i])\n",
    "    l.append(smaller[i])\n",
    "\n",
    "l.append('searchType')\n",
    "l.append('score')\n",
    "header = ','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.980000% \\ the estimated remaining time is roughly: 0:00:00.053406 \\ total elapsed time: 0:08:54.005472"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.990000% \\ the estimated remaining time is roughly: 0:00:00 \\ total elapsed time: 0:08:54.057404"
     ]
    }
   ],
   "source": [
    "for i in range(len(dic_bases)):\n",
    "    marker = time.time()\n",
    "    num_tasks = len(dic_bases[i])\n",
    "    result = []\n",
    "    c, elapsed_time = 0, 0\n",
    "    for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases[i])):\n",
    "        result.append(x)\n",
    "        c += 1\n",
    "        elapsed_time = time.time() - marker\n",
    "        done = float(j)/num_tasks\n",
    "        estimated = str(datetime.timedelta(seconds=(num_tasks -c)*(elapsed_time/c)))\n",
    "        sys.stderr.write('\\rdone: {:%} \\ the estimated remaining time is roughly: {} \\ total elapsed time: {}'.format(done, estimated, str(datetime.timedelta(seconds=time.time() - marker))))\n",
    "    f = open(targetBase + bases[i].split('/')[-1], 'w')\n",
    "    f.write(header + '\\n')\n",
    "    for line in result:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de execução: 541.3843970298767 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo total de execução: {} secs\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_A</th>\n",
       "      <th>seq_B</th>\n",
       "      <th>nome_A</th>\n",
       "      <th>nome_B</th>\n",
       "      <th>nome_mae_A</th>\n",
       "      <th>nome_mae_B</th>\n",
       "      <th>dt_nasc_A</th>\n",
       "      <th>dt_nasc_B</th>\n",
       "      <th>sexo_A</th>\n",
       "      <th>sexo_B</th>\n",
       "      <th>searchType</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>CAIO FURLAN CRESPO</td>\n",
       "      <td>CAIO FURLAN CRESPO</td>\n",
       "      <td>ELEN CRISTINA DE OLIVEIRA CARVALHO</td>\n",
       "      <td>ELEN CRISTINA DE OLIVEIRA CARVALHO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20061015</td>\n",
       "      <td>20061015</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1551</td>\n",
       "      <td>1551</td>\n",
       "      <td>YASMIM CAROLINA LOPES GONCALVES</td>\n",
       "      <td>YASMIM CAROLINA LOPES GONCALVES</td>\n",
       "      <td>JOANA FATIMA AYRES</td>\n",
       "      <td>JOANA FATIMA AYRES</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080117</td>\n",
       "      <td>20080117</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640</td>\n",
       "      <td>1640</td>\n",
       "      <td>EMILLY SEABRA DIAS</td>\n",
       "      <td>EMILLY SEABRA DIAS</td>\n",
       "      <td>SIONE CONCEICAO</td>\n",
       "      <td>SIONE CONCEICAO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080710</td>\n",
       "      <td>20080710</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1682</td>\n",
       "      <td>1682</td>\n",
       "      <td>KAROLYNE YASMIN MARQUES GOMES</td>\n",
       "      <td>KAROLYNE YASMIN MARQUES GOMES</td>\n",
       "      <td>MARIA FELISE NASCIMENTO</td>\n",
       "      <td>MARIA FELISE NASCIMENTO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080814</td>\n",
       "      <td>20080814</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>JOSIANE DOS SANTOS FERREIRA</td>\n",
       "      <td>JOSIANE DOS SANTOS FERREIRA</td>\n",
       "      <td>ALDENIRA RODRIGUES SANTOS</td>\n",
       "      <td>ALDENIRA RODRIGUES SANTOS</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080126</td>\n",
       "      <td>20080126</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq_A seq_B                           nome_A  \\\n",
       "0  1073  1073               CAIO FURLAN CRESPO   \n",
       "1  1551  1551  YASMIM CAROLINA LOPES GONCALVES   \n",
       "2  1640  1640               EMILLY SEABRA DIAS   \n",
       "3  1682  1682    KAROLYNE YASMIN MARQUES GOMES   \n",
       "4  1413  1413      JOSIANE DOS SANTOS FERREIRA   \n",
       "\n",
       "                            nome_B                          nome_mae_A  \\\n",
       "0               CAIO FURLAN CRESPO  ELEN CRISTINA DE OLIVEIRA CARVALHO   \n",
       "1  YASMIM CAROLINA LOPES GONCALVES                  JOANA FATIMA AYRES   \n",
       "2               EMILLY SEABRA DIAS                     SIONE CONCEICAO   \n",
       "3    KAROLYNE YASMIN MARQUES GOMES             MARIA FELISE NASCIMENTO   \n",
       "4      JOSIANE DOS SANTOS FERREIRA           ALDENIRA RODRIGUES SANTOS   \n",
       "\n",
       "                           nome_mae_B dt_nasc_A dt_nasc_B    sexo_A    sexo_B  \\\n",
       "0  ELEN CRISTINA DE OLIVEIRA CARVALHO         1         1  20061015  20061015   \n",
       "1                  JOANA FATIMA AYRES         2         2  20080117  20080117   \n",
       "2                     SIONE CONCEICAO         2         2  20080710  20080710   \n",
       "3             MARIA FELISE NASCIMENTO         2         2  20080814  20080814   \n",
       "4           ALDENIRA RODRIGUES SANTOS         2         2  20080126  20080126   \n",
       "\n",
       "          searchType score  \n",
       "0  searchExactPerson   1.0  \n",
       "1  searchExactPerson   1.0  \n",
       "2  searchExactPerson   1.0  \n",
       "3  searchExactPerson   1.0  \n",
       "4  searchExactPerson   1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.read.csv('../../../../../0_global_results/fd-cidacs-rl/legacy/part-00000-606cf15c-b1ef-4370-8b8b-2dbd69714870-c000.csv', header=True)\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|       searchType|count|\n",
      "+-----------------+-----+\n",
      "|searchFuzzyPerson| 4978|\n",
      "|searchExactPerson| 5022|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('searchType').groupBy('searchType').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
