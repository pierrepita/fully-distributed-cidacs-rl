{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '50000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listPath(path, recur=False, pattern=None, partitioned=False):\n",
    "    result = []\n",
    "    if path.startswith('hdfs'): \n",
    "        result = hdfs.ls(path, recursive=recur)\n",
    "    else:\n",
    "        if recur:\n",
    "            bases = []\n",
    "            for root, dirnames, filenames in os.walk(path):\n",
    "                bases += [root + '/' + x for x in filenames]\n",
    "            result = bases\n",
    "        else:\n",
    "            result = os.listdir(path)\n",
    "    if partitioned:\n",
    "        result = ['/'.join(x.split('/')[:-1]) for x in result if partitioned in x]\n",
    "        result = list(set(result))\n",
    "    if pattern:\n",
    "        result = [x for x in result if x.endswith(pattern)]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base to read,  write and es index\n",
    "# Paths need to end with '/'\n",
    "sourceFileName = \".csv\"\n",
    "sourceBase = \"../../../../../0_global_data/fd-cidacs-rl/sinthetic-datasets-b-legacy/sinthetic-datasets-b-\"+size+\".csv/\" # Example: hdfs:///npd/trusted/data/base_sim/05_linkage_extraction/\n",
    "targetBase = \"../../../../../0_global_results/fd-cidacs-rl/legacy/\" # Example: hdfs:///npd/refined/data/linkage_base_sim_x_base_sinasc/\n",
    "index_name = \"fd-cidacs-rl-legacy\" # Example: sinasc_maes_2001a2015_dtnascmae_nulo\n",
    "# hdfs.mkdir(targetBase)\n",
    "os.system('mkdir ' + targetBase)\n",
    "bases = listPath(sourceBase, pattern=sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-624f7141-600a-42d2-be81-4d63f1384b63-c000.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic search and start thread pool\n",
    "ncores = 4\n",
    "pool = ThreadPool(ncores)\n",
    "es = Elasticsearch('http://localhost:9200', maxsize=ncores, timeout=30, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for reference\n",
    "indexedBaseHeader = \"A\" # Example: sinasc\n",
    "sourceBaseHeader = \"B\" # Example: sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>NAYLLA SHAIANNY DE SOUSA RODRIGUES</td>\n",
       "      <td>MARIA REGINA DOS SANTOS</td>\n",
       "      <td>20080303</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>JOAO VICTOR MOREIRA SANTOS</td>\n",
       "      <td>JULIANA DA SILVA FREIRE</td>\n",
       "      <td>20071129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156</td>\n",
       "      <td>ANGEL GABRIEL DA SILVA SANTOS</td>\n",
       "      <td>NARRARA NATIELE FIDALGO</td>\n",
       "      <td>20071128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>MARIELLI DE JESUS OLIVEIRA</td>\n",
       "      <td>LEILA MARIA DA SILVA BENTO</td>\n",
       "      <td>20080221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "      <td>AMANDA CARVALHO DA SILVA</td>\n",
       "      <td>MARCIA GON€ALVES DAS SANTOS</td>\n",
       "      <td>20080412</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>230</td>\n",
       "      <td>ALINE FERREIRA BARROS</td>\n",
       "      <td>MARIA NAZARE DOS SANTOS</td>\n",
       "      <td>20080314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>306</td>\n",
       "      <td>KELVI JESUS DE SOUZA</td>\n",
       "      <td>ELINETE DOS ANJOS SOUSA</td>\n",
       "      <td>20070409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>321</td>\n",
       "      <td>NICOLAS OLIVEIRA DE FREITAS</td>\n",
       "      <td>DANIELE DA SILVA MATOS</td>\n",
       "      <td>20070128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>328</td>\n",
       "      <td>MARIA CLARA BISPO SANTOS</td>\n",
       "      <td>FRANCILENE ZACARIAS DA COSTA</td>\n",
       "      <td>20071026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>387</td>\n",
       "      <td>JENIFER VIEIRA DOS SANTOS</td>\n",
       "      <td>EVANISIA DE JESUS RAMOS</td>\n",
       "      <td>20061208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                              nome_b  \\\n",
       "0          58  NAYLLA SHAIANNY DE SOUSA RODRIGUES   \n",
       "1          76          JOAO VICTOR MOREIRA SANTOS   \n",
       "2         156       ANGEL GABRIEL DA SILVA SANTOS   \n",
       "3         168          MARIELLI DE JESUS OLIVEIRA   \n",
       "4         204            AMANDA CARVALHO DA SILVA   \n",
       "5         230               ALINE FERREIRA BARROS   \n",
       "6         306                KELVI JESUS DE SOUZA   \n",
       "7         321         NICOLAS OLIVEIRA DE FREITAS   \n",
       "8         328            MARIA CLARA BISPO SANTOS   \n",
       "9         387           JENIFER VIEIRA DOS SANTOS   \n",
       "\n",
       "                     nome_mae_b dt_nasc_b sexo_b  \n",
       "0       MARIA REGINA DOS SANTOS  20080303      2  \n",
       "1       JULIANA DA SILVA FREIRE  20071129      1  \n",
       "2       NARRARA NATIELE FIDALGO  20071128      1  \n",
       "3    LEILA MARIA DA SILVA BENTO  20080221      2  \n",
       "4   MARCIA GON€ALVES DAS SANTOS  20080412      2  \n",
       "5       MARIA NAZARE DOS SANTOS  20080314      2  \n",
       "6       ELINETE DOS ANJOS SOUSA  20070409      1  \n",
       "7        DANIELE DA SILVA MATOS  20070128      1  \n",
       "8  FRANCILENE ZACARIAS DA COSTA  20071026      2  \n",
       "9       EVANISIA DE JESUS RAMOS  20061208      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(sourceBase, header=True).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bases = []\n",
    "for source in bases:\n",
    "    # Open csv base\n",
    "    with open(sourceBase + source, 'r') as base:\n",
    "        dic_base = list()\n",
    "        header = True\n",
    "        #If csv contains header as first line, skip it\n",
    "        for l in base:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            # Split csv line\n",
    "            l = l.replace('\\n', '').split(',')\n",
    "            # Get each char\n",
    "            seq = l[0].strip()\n",
    "            nome_b = l[1].strip()\n",
    "            nome_mae_b = l[2].strip()\n",
    "            dt_nasc_b = l[3].strip()\n",
    "            sexo_b = l[4].strip()\n",
    "            \n",
    "\n",
    "            # If all fields are blanks, then don't add the register, add it otherwise.\n",
    "            if not (dt_nasc_b == '' and nome_b == '' and nome_mae_b == '' and sexo_b == ''):\n",
    "                content = {\n",
    "                'seq':seq,\n",
    "                'nome_b':unicode(nome_b),\n",
    "                'nome_mae_b':unicode(nome_mae_b),\n",
    "                'dt_nasc_b':unicode(dt_nasc_b),\n",
    "                'sexo_b':unicode(sexo_b)\n",
    "                }\n",
    "                dic_base.append(content)\n",
    "    dic_bases.append(dic_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-624f7141-600a-42d2-be81-4d63f1384b63-c000.csv 50000\n"
     ]
    }
   ],
   "source": [
    "# Number of registers for each base\n",
    "for i in range(len(dic_bases)):\n",
    "    print(bases[i].split('/')[-1], len(dic_bases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exact search on elastic search function\n",
    "def searchExactPerson(nome_b, nome_mae_b, sexo_b, startId=0):\n",
    "    \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'nome_a': nome_b}},\n",
    "                    {'match': {'nome_mae_a': nome_mae_b}},\n",
    "                    {'match': {'sexo_a': sexo_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']\n",
    "\n",
    "# Fuzzy search on elastic search function\n",
    "def searchFuzzyPerson(nome_b, nome_mae_b, dt_nasc_b, sexo_b, startId=0):\n",
    "  \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'nome_a': {'query': nome_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'nome_mae_a': {'query': nome_mae_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'sexo_a': {'query': sexo_b}}},\n",
    "                    {'term': {'dt_nasc_a': dt_nasc_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestCandidate(candidates, person):\n",
    "    if candidates:\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            score = compare(candidate['_source'], person)\n",
    "            scores.append((score, candidate))\n",
    "#         scores.sort(reverse=True) do not fit on python 3.x, it raises TypeError: '<' not supported between instances of 'dict' and 'dict'\n",
    "        scores.sort(key=lambda x: x[0], reverse=True) \n",
    "        bestCandidate = scores[0][1]\n",
    "        bestScore = scores[0][0]\n",
    "        bestCandidate['_source']['score'] = bestScore\n",
    "        return bestCandidate\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(candidate, source):\n",
    "    # Weights\n",
    "    nome_w = 5.0\n",
    "    nome_mae_w = 5.0\n",
    "    dt_nasc_w = 1.0\n",
    "    sexo_w = 3.0\n",
    "\n",
    "    nome_penalty = 0.02\n",
    "    nome_mae_penalty = 0.02\n",
    "    dt_nasc_penalty = 0.02\n",
    "    sexo_penalty = 0.02\n",
    "\n",
    "    # Max score\n",
    "    score_max = nome_w + nome_mae_w + dt_nasc_w + sexo_w\n",
    "\n",
    "    # Initialize scores and penalties\n",
    "    score_nome, score_nome_mae, score_dt_nasc, score_sexo, penalty = 0, 0, 0, 0, 0\n",
    "\n",
    "    # Compare addresses name with jaro distance\n",
    "    if candidate['nome_a'] == '' or source['nome_b'] == '':\n",
    "        score_max -= nome_w\n",
    "        penalty += nome_penalty\n",
    "    else:\n",
    "        score_nome = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_w\n",
    "\n",
    "\n",
    "    if candidate['nome_mae_a'] == '' or source['nome_mae_b'] == '':\n",
    "        score_max -= nome_mae_w\n",
    "        penalty += nome_mae_penalty\n",
    "    else:\n",
    "        score_nome_mae = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_mae_w\n",
    "\n",
    "    if candidate['dt_nasc_a'] == '' or source['dt_nasc_b'] == '':\n",
    "        score_max -= dt_nasc_w\n",
    "        penalty += dt_nasc_penalty\n",
    "    else:\n",
    "        score_dt_nasc = (1.0 - float(jellyfish.hamming_distance(candidate['dt_nasc_a'], source['dt_nasc_b'])) / max(len(candidate['dt_nasc_a']), len(source['dt_nasc_b']))) * dt_nasc_w\n",
    "\n",
    "\n",
    "   # Compare sex\n",
    "    if candidate['sexo_a'] == '' or source['sexo_b'] == '' :\n",
    "        score_max -= sexo_w\n",
    "        penalty += sexo_penalty\n",
    "    elif candidate['sexo_a'] == source['sexo_b'] :\n",
    "        score_sexo += sexo_w\n",
    "            \n",
    "    score = ((score_nome + score_nome_mae + score_dt_nasc + score_sexo) / score_max) - penalty\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cidacsrl(source):\n",
    "#     print(source)\n",
    "    result = ''\n",
    "    #Perform exact search\n",
    "    candidates = searchExactPerson(nome_b=source['nome_b'],\n",
    "                                   nome_mae_b=source['nome_mae_b'],\n",
    "                                   sexo_b=source['sexo_b'])\n",
    "    \n",
    "    bestCandidate = findBestCandidate(candidates, source)\n",
    "    \n",
    "    if candidates and bestCandidate['_source']['score'] >= .95:\n",
    "            \n",
    "        score = str(bestCandidate['_source']['score'])\n",
    "\n",
    "        searchType = 'searchExactPerson'\n",
    "\n",
    "        fields = [bestCandidate['_id'], source['seq'],\n",
    "                  bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                  bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                  bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                  bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'],\n",
    "                  searchType, score]\n",
    "        result = ','.join(fields) + '\\n'\n",
    "\n",
    "    # If no candidate is selected, perform fuzzy search\n",
    "    else:\n",
    "        candidates = searchFuzzyPerson(nome_b=source['nome_b'],\n",
    "                                       nome_mae_b=source['nome_mae_b'],\n",
    "                                       sexo_b=source['sexo_b'],\n",
    "                                       dt_nasc_b=source['dt_nasc_b'])\n",
    "        \n",
    "        bestCandidate = findBestCandidate(candidates, source)\n",
    "        if bestCandidate:\n",
    "            score = str(bestCandidate['_source']['score'])\n",
    "            \n",
    "            searchType = 'searchFuzzyPerson'\n",
    "            \n",
    "            fields = [bestCandidate['_id'], source['seq'], \n",
    "                      bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                      bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                      bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                      bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'], \n",
    "                      searchType, score]\n",
    "            result = ','.join(fields) + '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datamart header\n",
    "headerFields = ['seq', 'nome', 'nome_mae', 'dt_nasc', 'sexo']\n",
    "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
    "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
    "l = []\n",
    "for i in range(len(larger)):\n",
    "    l.append(larger[i])\n",
    "    l.append(smaller[i])\n",
    "\n",
    "l.append('searchType')\n",
    "l.append('score')\n",
    "header = ','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.994000% \\ the estimated remaining time is roughly: 0:00:00.076001 \\ total elapsed time: 0:31:39.941885"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.998000% \\ the estimated remaining time is roughly: 0:00:00 \\ total elapsed time: 0:31:40.164818.133229"
     ]
    }
   ],
   "source": [
    "for i in range(len(dic_bases)):\n",
    "    marker = time.time()\n",
    "    num_tasks = len(dic_bases[i])\n",
    "    result = []\n",
    "    c, elapsed_time = 0, 0\n",
    "    for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases[i])):\n",
    "        result.append(x)\n",
    "        c += 1\n",
    "        elapsed_time = time.time() - marker\n",
    "        done = float(j)/num_tasks\n",
    "        estimated = str(datetime.timedelta(seconds=(num_tasks -c)*(elapsed_time/c)))\n",
    "        sys.stderr.write('\\rdone: {:%} \\ the estimated remaining time is roughly: {} \\ total elapsed time: {}'.format(done, estimated, str(datetime.timedelta(seconds=time.time() - marker))))\n",
    "    f = open(targetBase + bases[i].split('/')[-1], 'w')\n",
    "    f.write(header + '\\n')\n",
    "    for line in result:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de execução: 1906.223349571228 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo total de execução: {} secs\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_A</th>\n",
       "      <th>seq_B</th>\n",
       "      <th>nome_A</th>\n",
       "      <th>nome_B</th>\n",
       "      <th>nome_mae_A</th>\n",
       "      <th>nome_mae_B</th>\n",
       "      <th>dt_nasc_A</th>\n",
       "      <th>dt_nasc_B</th>\n",
       "      <th>sexo_A</th>\n",
       "      <th>sexo_B</th>\n",
       "      <th>searchType</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>ANGEL GABRIEL DA SILVA SANTOS</td>\n",
       "      <td>ANGEL GABRIEL DA SILVA SANTOS</td>\n",
       "      <td>NARRARA NATIELE FIDALGO</td>\n",
       "      <td>NARRARA NATIELE FIDALGO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20071128</td>\n",
       "      <td>20071128</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>NAYLLA SHAIANNY DE SOUSA RODRIGUES</td>\n",
       "      <td>NAYLLA SHAIANNY DE SOUSA RODRIGUES</td>\n",
       "      <td>MARIA REGINA DOS SANTOS</td>\n",
       "      <td>MARIA REGINA DOS SANTOS</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080303</td>\n",
       "      <td>20080303</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>AMANDA CARVALHO DA SILVA</td>\n",
       "      <td>AMANDA CARVALHO DA SILVA</td>\n",
       "      <td>MARCIA GON€ALVES DAS SANTOS</td>\n",
       "      <td>MARCIA GON€ALVES DAS SANTOS</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080412</td>\n",
       "      <td>20080412</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>JOAO VICTOR MOREIRA SANTOS</td>\n",
       "      <td>JOAO VICTOR MOREIRA SANTOS</td>\n",
       "      <td>JULIANA DA SILVA FREIRE</td>\n",
       "      <td>JULIANA DA SILVA FREIRE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20071129</td>\n",
       "      <td>20071129</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>MARIELLI DE JESUS OLIVEIRA</td>\n",
       "      <td>MARIELLI DE JESUS OLIVEIRA</td>\n",
       "      <td>LEILA MARIA DA SILVA BENTO</td>\n",
       "      <td>LEILA MARIA DA SILVA BENTO</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20080221</td>\n",
       "      <td>20080221</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq_A seq_B                              nome_A  \\\n",
       "0   156   156       ANGEL GABRIEL DA SILVA SANTOS   \n",
       "1    58    58  NAYLLA SHAIANNY DE SOUSA RODRIGUES   \n",
       "2   204   204            AMANDA CARVALHO DA SILVA   \n",
       "3    76    76          JOAO VICTOR MOREIRA SANTOS   \n",
       "4   168   168          MARIELLI DE JESUS OLIVEIRA   \n",
       "\n",
       "                               nome_B                   nome_mae_A  \\\n",
       "0       ANGEL GABRIEL DA SILVA SANTOS      NARRARA NATIELE FIDALGO   \n",
       "1  NAYLLA SHAIANNY DE SOUSA RODRIGUES      MARIA REGINA DOS SANTOS   \n",
       "2            AMANDA CARVALHO DA SILVA  MARCIA GON€ALVES DAS SANTOS   \n",
       "3          JOAO VICTOR MOREIRA SANTOS      JULIANA DA SILVA FREIRE   \n",
       "4          MARIELLI DE JESUS OLIVEIRA   LEILA MARIA DA SILVA BENTO   \n",
       "\n",
       "                    nome_mae_B dt_nasc_A dt_nasc_B    sexo_A    sexo_B  \\\n",
       "0      NARRARA NATIELE FIDALGO         1         1  20071128  20071128   \n",
       "1      MARIA REGINA DOS SANTOS         2         2  20080303  20080303   \n",
       "2  MARCIA GON€ALVES DAS SANTOS         2         2  20080412  20080412   \n",
       "3      JULIANA DA SILVA FREIRE         1         1  20071129  20071129   \n",
       "4   LEILA MARIA DA SILVA BENTO         2         2  20080221  20080221   \n",
       "\n",
       "          searchType score  \n",
       "0  searchExactPerson   1.0  \n",
       "1  searchExactPerson   1.0  \n",
       "2  searchExactPerson   1.0  \n",
       "3  searchExactPerson   1.0  \n",
       "4  searchExactPerson   1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.read.csv('../../../../../0_global_results/fd-cidacs-rl/legacy/part-00000-624f7141-600a-42d2-be81-4d63f1384b63-c000.csv', header=True)\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|       searchType|count|\n",
      "+-----------------+-----+\n",
      "|searchFuzzyPerson|24293|\n",
      "|searchExactPerson|25707|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('searchType').groupBy('searchType').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
