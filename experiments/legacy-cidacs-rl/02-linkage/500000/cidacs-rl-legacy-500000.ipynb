{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "if sys.version_info[0] >= 3:\n",
    "    unicode = str\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '500000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listPath(path, recur=False, pattern=None, partitioned=False):\n",
    "    result = []\n",
    "    if path.startswith('hdfs'): \n",
    "        result = hdfs.ls(path, recursive=recur)\n",
    "    else:\n",
    "        if recur:\n",
    "            bases = []\n",
    "            for root, dirnames, filenames in os.walk(path):\n",
    "                bases += [root + '/' + x for x in filenames]\n",
    "            result = bases\n",
    "        else:\n",
    "            result = os.listdir(path)\n",
    "    if partitioned:\n",
    "        result = ['/'.join(x.split('/')[:-1]) for x in result if partitioned in x]\n",
    "        result = list(set(result))\n",
    "    if pattern:\n",
    "        result = [x for x in result if x.endswith(pattern)]        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base to read,  write and es index\n",
    "# Paths need to end with '/'\n",
    "sourceFileName = \".csv\"\n",
    "sourceBase = \"../../../../../0_global_data/fd-cidacs-rl/sinthetic-datasets-b-legacy/sinthetic-datasets-b-\"+size+\".csv/\" # Example: hdfs:///npd/trusted/data/base_sim/05_linkage_extraction/\n",
    "targetBase = \"../../../../../0_global_results/fd-cidacs-rl/legacy/\" # Example: hdfs:///npd/refined/data/linkage_base_sim_x_base_sinasc/\n",
    "index_name = \"fd-cidacs-rl-legacy\" # Example: sinasc_maes_2001a2015_dtnascmae_nulo\n",
    "# hdfs.mkdir(targetBase)\n",
    "os.system('mkdir ' + targetBase)\n",
    "bases = listPath(sourceBase, pattern=sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-8710a713-9a67-48ab-a586-8208446f1e4c-c000.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load elastic search and start thread pool\n",
    "ncores = 4\n",
    "pool = ThreadPool(ncores)\n",
    "es = Elasticsearch('http://localhost:9200', maxsize=ncores, timeout=30, max_retries=10, retry_on_timeout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for reference\n",
    "indexedBaseHeader = \"A\" # Example: sinasc\n",
    "sourceBaseHeader = \"B\" # Example: sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>20061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>20071107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>VINICIUS DA SILVA SOUZA</td>\n",
       "      <td>ELIZANGELA LIMA DA SILVA</td>\n",
       "      <td>20071008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>LUAN FERREIRA DO NASCIMENTO</td>\n",
       "      <td>KEZIA NUNES GALDINO MONTEIRO</td>\n",
       "      <td>20080128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>JOAO PEDRO BATISTA DOS SANTOS</td>\n",
       "      <td>SOILA COSTA DA SILVA</td>\n",
       "      <td>20070903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>AMANDA BANDEIRA BARRA</td>\n",
       "      <td>EDINEIA ESQUERDO BRAGA</td>\n",
       "      <td>20070610</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>VITOR CORDEIRO DOS SANTOS</td>\n",
       "      <td>SUELLI RIBEIRO SALUSTINO</td>\n",
       "      <td>20070902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>RHANIELLY GONCALVES GOMES</td>\n",
       "      <td>MARIA DA CONCEICAO RODRIGUES</td>\n",
       "      <td>20071011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>LUANA GLESIA DIAS OLIVEIRA</td>\n",
       "      <td>FRANCISCA CAMARA FERREIRA</td>\n",
       "      <td>20080516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>JENNIFER YARA EDUARDO SILVA</td>\n",
       "      <td>JUSSARA DA SILVA MELO SOUZA</td>\n",
       "      <td>20071123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                              nome_b  \\\n",
       "0           2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "1           3       FABRICIO RODRIGUES DOS SANTOS   \n",
       "2           4             VINICIUS DA SILVA SOUZA   \n",
       "3           5         LUAN FERREIRA DO NASCIMENTO   \n",
       "4           7       JOAO PEDRO BATISTA DOS SANTOS   \n",
       "5           8               AMANDA BANDEIRA BARRA   \n",
       "6          16           VITOR CORDEIRO DOS SANTOS   \n",
       "7          17           RHANIELLY GONCALVES GOMES   \n",
       "8          23          LUANA GLESIA DIAS OLIVEIRA   \n",
       "9          24         JENNIFER YARA EDUARDO SILVA   \n",
       "\n",
       "                     nome_mae_b dt_nasc_b sexo_b  \n",
       "0  FRANCILEIDE DOS SANTOS ALVES  20061102      1  \n",
       "1      MARCELA MACHADO DA SILVA  20071107      1  \n",
       "2      ELIZANGELA LIMA DA SILVA  20071008      1  \n",
       "3  KEZIA NUNES GALDINO MONTEIRO  20080128      1  \n",
       "4          SOILA COSTA DA SILVA  20070903      1  \n",
       "5        EDINEIA ESQUERDO BRAGA  20070610      2  \n",
       "6      SUELLI RIBEIRO SALUSTINO  20070902      1  \n",
       "7  MARIA DA CONCEICAO RODRIGUES  20071011      2  \n",
       "8     FRANCISCA CAMARA FERREIRA  20080516      2  \n",
       "9   JUSSARA DA SILVA MELO SOUZA  20071123      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(sourceBase, header=True).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bases = []\n",
    "for source in bases:\n",
    "    # Open csv base\n",
    "    with open(sourceBase + source, 'r') as base:\n",
    "        dic_base = list()\n",
    "        header = True\n",
    "        #If csv contains header as first line, skip it\n",
    "        for l in base:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            # Split csv line\n",
    "            l = l.replace('\\n', '').split(',')\n",
    "            # Get each char\n",
    "            seq = l[0].strip()\n",
    "            nome_b = l[1].strip()\n",
    "            nome_mae_b = l[2].strip()\n",
    "            dt_nasc_b = l[3].strip()\n",
    "            sexo_b = l[4].strip()\n",
    "            \n",
    "\n",
    "            # If all fields are blanks, then don't add the register, add it otherwise.\n",
    "            if not (dt_nasc_b == '' and nome_b == '' and nome_mae_b == '' and sexo_b == ''):\n",
    "                content = {\n",
    "                'seq':seq,\n",
    "                'nome_b':unicode(nome_b),\n",
    "                'nome_mae_b':unicode(nome_mae_b),\n",
    "                'dt_nasc_b':unicode(dt_nasc_b),\n",
    "                'sexo_b':unicode(sexo_b)\n",
    "                }\n",
    "                dic_base.append(content)\n",
    "    dic_bases.append(dic_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-8710a713-9a67-48ab-a586-8208446f1e4c-c000.csv 500000\n"
     ]
    }
   ],
   "source": [
    "# Number of registers for each base\n",
    "for i in range(len(dic_bases)):\n",
    "    print(bases[i].split('/')[-1], len(dic_bases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exact search on elastic search function\n",
    "def searchExactPerson(nome_b, nome_mae_b, sexo_b, startId=0):\n",
    "    \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'must': [\n",
    "                    {'match': {'nome_a': nome_b}},\n",
    "                    {'match': {'nome_mae_a': nome_mae_b}},\n",
    "                    {'match': {'sexo_a': sexo_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']\n",
    "\n",
    "# Fuzzy search on elastic search function\n",
    "def searchFuzzyPerson(nome_b, nome_mae_b, dt_nasc_b, sexo_b, startId=0):\n",
    "  \n",
    "    global es\n",
    "    \n",
    "    content = {\n",
    "        'size': 100,\n",
    "        'query': {\n",
    "            'bool': {\n",
    "                'should': [\n",
    "                    {'match': {'nome_a': {'query': nome_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'3.0'}}},\n",
    "                    {'match': {'nome_mae_a': {'query': nome_mae_b, 'fuzziness':'AUTO', 'operator':'or', 'boost':'2.0'}}},\n",
    "                    {'match': {'sexo_a': {'query': sexo_b}}},\n",
    "                    {'term': {'dt_nasc_a': dt_nasc_b}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    force = True\n",
    "    while force:\n",
    "        try:\n",
    "            res = es.search(index=index_name, body=content)\n",
    "            force = False\n",
    "        except:\n",
    "            pass\n",
    "    return res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestCandidate(candidates, person):\n",
    "    if candidates:\n",
    "        scores = []\n",
    "        for candidate in candidates:\n",
    "            score = compare(candidate['_source'], person)\n",
    "            scores.append((score, candidate))\n",
    "#         scores.sort(reverse=True) do not fit on python 3.x, it raises TypeError: '<' not supported between instances of 'dict' and 'dict'\n",
    "        scores.sort(key=lambda x: x[0], reverse=True) \n",
    "        bestCandidate = scores[0][1]\n",
    "        bestScore = scores[0][0]\n",
    "        bestCandidate['_source']['score'] = bestScore\n",
    "        return bestCandidate\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(candidate, source):\n",
    "    # Weights\n",
    "    nome_w = 5.0\n",
    "    nome_mae_w = 5.0\n",
    "    dt_nasc_w = 1.0\n",
    "    sexo_w = 3.0\n",
    "\n",
    "    nome_penalty = 0.02\n",
    "    nome_mae_penalty = 0.02\n",
    "    dt_nasc_penalty = 0.02\n",
    "    sexo_penalty = 0.02\n",
    "\n",
    "    # Max score\n",
    "    score_max = nome_w + nome_mae_w + dt_nasc_w + sexo_w\n",
    "\n",
    "    # Initialize scores and penalties\n",
    "    score_nome, score_nome_mae, score_dt_nasc, score_sexo, penalty = 0, 0, 0, 0, 0\n",
    "\n",
    "    # Compare addresses name with jaro distance\n",
    "    if candidate['nome_a'] == '' or source['nome_b'] == '':\n",
    "        score_max -= nome_w\n",
    "        penalty += nome_penalty\n",
    "    else:\n",
    "        score_nome = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_w\n",
    "\n",
    "\n",
    "    if candidate['nome_mae_a'] == '' or source['nome_mae_b'] == '':\n",
    "        score_max -= nome_mae_w\n",
    "        penalty += nome_mae_penalty\n",
    "    else:\n",
    "        score_nome_mae = jellyfish.jaro_winkler(candidate['nome_a'], source['nome_b']) * nome_mae_w\n",
    "\n",
    "    if candidate['dt_nasc_a'] == '' or source['dt_nasc_b'] == '':\n",
    "        score_max -= dt_nasc_w\n",
    "        penalty += dt_nasc_penalty\n",
    "    else:\n",
    "        score_dt_nasc = (1.0 - float(jellyfish.hamming_distance(candidate['dt_nasc_a'], source['dt_nasc_b'])) / max(len(candidate['dt_nasc_a']), len(source['dt_nasc_b']))) * dt_nasc_w\n",
    "\n",
    "\n",
    "   # Compare sex\n",
    "    if candidate['sexo_a'] == '' or source['sexo_b'] == '' :\n",
    "        score_max -= sexo_w\n",
    "        penalty += sexo_penalty\n",
    "    elif candidate['sexo_a'] == source['sexo_b'] :\n",
    "        score_sexo += sexo_w\n",
    "            \n",
    "    score = ((score_nome + score_nome_mae + score_dt_nasc + score_sexo) / score_max) - penalty\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cidacsrl(source):\n",
    "#     print(source)\n",
    "    result = ''\n",
    "    #Perform exact search\n",
    "    candidates = searchExactPerson(nome_b=source['nome_b'],\n",
    "                                   nome_mae_b=source['nome_mae_b'],\n",
    "                                   sexo_b=source['sexo_b'])\n",
    "    \n",
    "    bestCandidate = findBestCandidate(candidates, source)\n",
    "    \n",
    "    if candidates and bestCandidate['_source']['score'] >= .95:\n",
    "            \n",
    "        score = str(bestCandidate['_source']['score'])\n",
    "\n",
    "        searchType = 'searchExactPerson'\n",
    "\n",
    "        fields = [bestCandidate['_id'], source['seq'],\n",
    "                  bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                  bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                  bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                  bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'],\n",
    "                  searchType, score]\n",
    "        result = ','.join(fields) + '\\n'\n",
    "\n",
    "    # If no candidate is selected, perform fuzzy search\n",
    "    else:\n",
    "        candidates = searchFuzzyPerson(nome_b=source['nome_b'],\n",
    "                                       nome_mae_b=source['nome_mae_b'],\n",
    "                                       sexo_b=source['sexo_b'],\n",
    "                                       dt_nasc_b=source['dt_nasc_b'])\n",
    "        \n",
    "        bestCandidate = findBestCandidate(candidates, source)\n",
    "        if bestCandidate:\n",
    "            score = str(bestCandidate['_source']['score'])\n",
    "            \n",
    "            searchType = 'searchFuzzyPerson'\n",
    "            \n",
    "            fields = [bestCandidate['_id'], source['seq'], \n",
    "                      bestCandidate['_source']['nome_a'], source['nome_b'],\n",
    "                      bestCandidate['_source']['nome_mae_a'], source['nome_mae_b'],\n",
    "                      bestCandidate['_source']['sexo_a'], source['sexo_b'],\n",
    "                      bestCandidate['_source']['dt_nasc_a'], source['dt_nasc_b'], \n",
    "                      searchType, score]\n",
    "            result = ','.join(fields) + '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datamart header\n",
    "headerFields = ['seq', 'nome', 'nome_mae', 'dt_nasc', 'sexo']\n",
    "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
    "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
    "l = []\n",
    "for i in range(len(larger)):\n",
    "    l.append(larger[i])\n",
    "    l.append(smaller[i])\n",
    "\n",
    "l.append('searchType')\n",
    "l.append('score')\n",
    "header = ','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done: 99.999800% \\ the estimated remaining time is roughly: 0:00:00 \\ total elapsed time: 6:24:16.830817.823446205527"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dic_bases)):\n",
    "    marker = time.time()\n",
    "    num_tasks = len(dic_bases[i])\n",
    "    result = []\n",
    "    c, elapsed_time = 0, 0\n",
    "    for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases[i])):\n",
    "        result.append(x)\n",
    "        c += 1\n",
    "        elapsed_time = time.time() - marker\n",
    "        done = float(j)/num_tasks\n",
    "        estimated = str(datetime.timedelta(seconds=(num_tasks -c)*(elapsed_time/c)))\n",
    "        sys.stderr.write('\\rdone: {:%} \\ the estimated remaining time is roughly: {} \\ total elapsed time: {}'.format(done, estimated, str(datetime.timedelta(seconds=time.time() - marker))))\n",
    "    f = open(targetBase + bases[i].split('/')[-1], 'w')\n",
    "    f.write(header + '\\n')\n",
    "    for line in result:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de execução: 23070.82509827614 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo total de execução: {} secs\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_A</th>\n",
       "      <th>seq_B</th>\n",
       "      <th>nome_A</th>\n",
       "      <th>nome_B</th>\n",
       "      <th>nome_mae_A</th>\n",
       "      <th>nome_mae_B</th>\n",
       "      <th>dt_nasc_A</th>\n",
       "      <th>dt_nasc_B</th>\n",
       "      <th>sexo_A</th>\n",
       "      <th>sexo_B</th>\n",
       "      <th>searchType</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>LUAN FERREIRA DO NASCIMENTO</td>\n",
       "      <td>LUAN FERREIRA DO NASCIMENTO</td>\n",
       "      <td>KEZIA NUNES GALDINO MONTEIRO</td>\n",
       "      <td>KEZIA NUNES GALDINO MONTEIRO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20080128</td>\n",
       "      <td>20080128</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20061102</td>\n",
       "      <td>20061102</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>FABRICIO RODRIGUES DOS SANTOS</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>MARCELA MACHADO DA SILVA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20071107</td>\n",
       "      <td>20071107</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>AMANDA BANDEIRA BARRA</td>\n",
       "      <td>AMANDA BANDEIRA BARRA</td>\n",
       "      <td>EDINEIA ESQUERDO BRAGA</td>\n",
       "      <td>EDINEIA ESQUERDO BRAGA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20070610</td>\n",
       "      <td>20070610</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>VINICIUS DA SILVA SOUZA</td>\n",
       "      <td>VINICIUS DA SILVA SOUZA</td>\n",
       "      <td>ELIZANGELA LIMA DA SILVA</td>\n",
       "      <td>ELIZANGELA LIMA DA SILVA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20071008</td>\n",
       "      <td>20071008</td>\n",
       "      <td>searchExactPerson</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq_A seq_B                              nome_A  \\\n",
       "0     5     5         LUAN FERREIRA DO NASCIMENTO   \n",
       "1     2     2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "2     3     3       FABRICIO RODRIGUES DOS SANTOS   \n",
       "3     8     8               AMANDA BANDEIRA BARRA   \n",
       "4     4     4             VINICIUS DA SILVA SOUZA   \n",
       "\n",
       "                               nome_B                    nome_mae_A  \\\n",
       "0         LUAN FERREIRA DO NASCIMENTO  KEZIA NUNES GALDINO MONTEIRO   \n",
       "1  PEDRO HENRIQUE MARTINS DE CARVALHO  FRANCILEIDE DOS SANTOS ALVES   \n",
       "2       FABRICIO RODRIGUES DOS SANTOS      MARCELA MACHADO DA SILVA   \n",
       "3               AMANDA BANDEIRA BARRA        EDINEIA ESQUERDO BRAGA   \n",
       "4             VINICIUS DA SILVA SOUZA      ELIZANGELA LIMA DA SILVA   \n",
       "\n",
       "                     nome_mae_B dt_nasc_A dt_nasc_B    sexo_A    sexo_B  \\\n",
       "0  KEZIA NUNES GALDINO MONTEIRO         1         1  20080128  20080128   \n",
       "1  FRANCILEIDE DOS SANTOS ALVES         1         1  20061102  20061102   \n",
       "2      MARCELA MACHADO DA SILVA         1         1  20071107  20071107   \n",
       "3        EDINEIA ESQUERDO BRAGA         2         2  20070610  20070610   \n",
       "4      ELIZANGELA LIMA DA SILVA         1         1  20071008  20071008   \n",
       "\n",
       "          searchType score  \n",
       "0  searchExactPerson   1.0  \n",
       "1  searchExactPerson   1.0  \n",
       "2  searchExactPerson   1.0  \n",
       "3  searchExactPerson   1.0  \n",
       "4  searchExactPerson   1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.read.csv('../../../../../0_global_results/fd-cidacs-rl/legacy/part-00000-8710a713-9a67-48ab-a586-8208446f1e4c-c000.csv', header=True)\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|       searchType| count|\n",
      "+-----------------+------+\n",
      "|searchFuzzyPerson|242899|\n",
      "|searchExactPerson|257101|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('searchType').groupBy('searchType').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
